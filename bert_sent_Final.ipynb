{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "893242d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8441c87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Drasko they didn't cook half a bird you idiot ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Hopefully someone cooks Drasko in the next ep ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>of course you were born in serbia...you're as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>These girls are the equivalent of the irritati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>RT @YesYoureRacist: At least you're only a tin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  class\n",
       "0           0  Drasko they didn't cook half a bird you idiot ...      1\n",
       "1           1  Hopefully someone cooks Drasko in the next ep ...      1\n",
       "2           2  of course you were born in serbia...you're as ...      1\n",
       "3           3  These girls are the equivalent of the irritati...      1\n",
       "4           4  RT @YesYoureRacist: At least you're only a tin...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data into DataFrame \n",
    "df = pd.read_csv('balanced_data_combined.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b32b3f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "895c6d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Drasko they didn't cook half a bird you idiot ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Hopefully someone cooks Drasko in the next ep ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>of course you were born in serbia...you're as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>These girls are the equivalent of the irritati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>RT @YesYoureRacist: At least you're only a tin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              tweet  target\n",
       "0           0  Drasko they didn't cook half a bird you idiot ...       1\n",
       "1           1  Hopefully someone cooks Drasko in the next ep ...       1\n",
       "2           2  of course you were born in serbia...you're as ...       1\n",
       "3           3  These girls are the equivalent of the irritati...       1\n",
       "4           4  RT @YesYoureRacist: At least you're only a tin...       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.rename(columns={'text': 'tweet', 'class': 'target'})\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b81831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= df1.drop('Unnamed: 0', axis=1)\n",
    "df1.dropna(subset=['tweet'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f02795d",
   "metadata": {},
   "source": [
    "# Clean tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c4379da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(df, col):\n",
    "    \n",
    "    df[col] = df[col].apply(lambda x: re.sub(r'@[\\S]+', ' ', str(x)))\n",
    "    df[col] = df[col].apply(lambda x: re.sub(r'&[\\S]+?;', ' ', str(x)))\n",
    "    df[col] = df[col].apply(lambda x: re.sub(r'#', ' ', str(x)))\n",
    "    df[col] = df[col].apply(lambda x: re.sub(r'(\\bRT\\b|\\bQT\\b)', ' ', str(x)))\n",
    "    df[col] = df[col].apply(lambda x: re.sub(r'http[\\S]+', ' ', str(x)))\n",
    "    df[col] = df[col].apply(lambda x: re.sub(r'[^\\w\\s]', r'', str(x)))\n",
    "    df[col] = df[col].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "    df[col] = df[col].apply(lambda x: re.sub(r'\\w*\\d\\w*', r' ', str(x)))\n",
    "    df[col] = df[col].apply(lambda x: re.sub(r'\\s\\s+', ' ', str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d02d8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drasko they didnt cook half a bird you idiot mkr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hopefully someone cooks drasko in the next ep ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of course you were born in serbiayoure as fuck...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>these girls are the equivalent of the irritati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>at least youre only a tiny bit racist im not r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  target\n",
       "0   drasko they didnt cook half a bird you idiot mkr       1\n",
       "1  hopefully someone cooks drasko in the next ep ...       1\n",
       "2  of course you were born in serbiayoure as fuck...       1\n",
       "3  these girls are the equivalent of the irritati...       1\n",
       "4  at least youre only a tiny bit racist im not r...       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_tweet(df1, 'tweet')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bac02b1",
   "metadata": {},
   "source": [
    "# Bert tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b74dad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                          do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdc6f19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"sent_bert_token_length\"] = df1[\"tweet\"].apply(lambda x: len(tokenizer(x, add_special_tokens=False)[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb971c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>target</th>\n",
       "      <th>sent_bert_token_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drasko they didnt cook half a bird you idiot mkr</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hopefully someone cooks drasko in the next ep ...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of course you were born in serbiayoure as fuck...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>these girls are the equivalent of the irritati...</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>at least youre only a tiny bit racist im not r...</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  target  \\\n",
       "0   drasko they didnt cook half a bird you idiot mkr       1   \n",
       "1  hopefully someone cooks drasko in the next ep ...       1   \n",
       "2  of course you were born in serbiayoure as fuck...       1   \n",
       "3  these girls are the equivalent of the irritati...       1   \n",
       "4  at least youre only a tiny bit racist im not r...       1   \n",
       "\n",
       "   sent_bert_token_length  \n",
       "0                      14  \n",
       "1                      13  \n",
       "2                      17  \n",
       "3                      18  \n",
       "4                      16  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c987b1c2",
   "metadata": {},
   "source": [
    "# Bert Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60e57b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from transformers import BertForSequenceClassification\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "115d5814",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    seed_val = 17\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    epochs = 5 \n",
    "    batch_size = 6\n",
    "    seq_length = 512\n",
    "    lr = 2e-5\n",
    "    eps = 1e-8\n",
    "    pretrained_model = 'bert-base-uncased'\n",
    "    test_size=0.15\n",
    "    random_state=42\n",
    "    add_special_tokens=True \n",
    "    return_attention_mask=True \n",
    "    pad_to_max_length=True \n",
    "    do_lower_case=False\n",
    "    return_tensors='pt'\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3130a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"seed_val\": config.seed_val,\n",
    "    \"device\":str(config.device),\n",
    "    \"epochs\":config.epochs, \n",
    "    \"batch_size\":config.batch_size,\n",
    "    \"seq_length\":config.seq_length,\n",
    "    \"lr\":config.lr,\n",
    "    \"eps\":config.eps,\n",
    "    \"pretrained_model\": config.pretrained_model,\n",
    "    \"test_size\":config.test_size,\n",
    "    \"random_state\":config.random_state,\n",
    "    \"add_special_tokens\":config.add_special_tokens,\n",
    "    \"return_attention_mask\":config.return_attention_mask,\n",
    "    \"pad_to_max_length\":config.pad_to_max_length,\n",
    "    \"do_lower_case\":config.do_lower_case,\n",
    "    \"return_tensors\":config.return_tensors,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "063070c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "device = config.device\n",
    "\n",
    "random.seed(config.seed_val)\n",
    "np.random.seed(config.seed_val)\n",
    "torch.manual_seed(config.seed_val)\n",
    "torch.cuda.manual_seed_all(config.seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04687767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df_, val_df = train_test_split(df1, \n",
    "                                    test_size=0.20, \n",
    "                                    random_state=config.random_state, stratify=df1['target'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b461629e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>target</th>\n",
       "      <th>sent_bert_token_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>and that proves what</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5844</th>\n",
       "      <td>my teacher always says has a man ever abused h...</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>whut btw im no sexist i jus mean same woman ba...</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4878</th>\n",
       "      <td>charlie sheen wants to return to two and a hal...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3162</th>\n",
       "      <td>waits for fanduel to hit me with the jig</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  target  \\\n",
       "1370                               and that proves what       1   \n",
       "5844  my teacher always says has a man ever abused h...       0   \n",
       "1620  whut btw im no sexist i jus mean same woman ba...       1   \n",
       "4878  charlie sheen wants to return to two and a hal...       0   \n",
       "3162           waits for fanduel to hit me with the jig       0   \n",
       "\n",
       "      sent_bert_token_length  \n",
       "1370                       4  \n",
       "5844                      26  \n",
       "1620                      29  \n",
       "4878                      11  \n",
       "3162                      12  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "193f0e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(config.pretrained_model, \n",
    "                                          do_lower_case=config.do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c00f66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/Users/manveerkaur/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    train_df_['tweet'].values, \n",
    "    add_special_tokens=config.add_special_tokens, \n",
    "    return_attention_mask=config.return_attention_mask, \n",
    "    pad_to_max_length=config.pad_to_max_length, \n",
    "    max_length=config.seq_length, \n",
    "    return_tensors=config.return_tensors\n",
    ")\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    val_df['tweet'].values, \n",
    "    add_special_tokens=config.add_special_tokens, \n",
    "    return_attention_mask=config.return_attention_mask, \n",
    "    pad_to_max_length=config.pad_to_max_length,\n",
    "    max_length=config.seq_length, \n",
    "    return_tensors=config.return_tensors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf3acd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(train_df_['target'].values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(val_df['target'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02c6914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6349408f-e4c8-442a-a031-72ddf31bc1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6668"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de04b2fd-296b-4f18-815f-8037c1ce37f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1667"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1047d542-ff90-4bd7-946b-09ded909306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict ={'hate': 1, 'not_hate':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e32b1d4-e2fa-4034-bec7-4a09ecf09710",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels = len(label_dict),\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e68110b4-6dca-412f-ae90-a70a79a25422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8cc3e44a-b583-446e-8b84-6aa3726fa5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# We Need two different dataloder\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train),\n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                              sampler=RandomSampler(dataset_val),\n",
    "                              batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6444629-2347-4cb8-a8a4-fbbc34ada4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf4f8209-88ad-4ecb-96f0-12e95a73373e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manveerkaur/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr = 1e-5, \n",
    "    eps = 1e-8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abcf3980-0f56-4518-a4d6-516d2f66170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps = 0,\n",
    "    num_training_steps = len(dataloader_train)*epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc169d48-41a0-405a-ad78-1ebdc69a9d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32834544-0183-4f7f-8e93-02767d3dcdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis = 1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fdc4d668-2961-4159-969d-4617e86b7675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis = 1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat == label]\n",
    "        y_true = labels_flat[labels_flat == label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds == label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78c1c560-1b36-4672-a1af-666aeae43bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5af513e-dcc5-4df5-82e8-da2d15da96c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in tqdm(dataloader_val):\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9bbfa0c9-0dae-4a34-8e12-1dd9863df6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]\n",
      "Epoch 1:   0%|                                          | 0/209 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:   0%|                     | 0/209 [00:54<?, ?it/s, training_loss=0.271]\u001b[A\n",
      "Epoch 1:   0%|           | 1/209 [00:54<3:10:31, 54.96s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 1:   0%|           | 1/209 [01:47<3:10:31, 54.96s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:   1%|           | 2/209 [01:47<3:04:40, 53.53s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:   1%|           | 2/209 [02:39<3:04:40, 53.53s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:   1%|▏          | 3/209 [02:39<3:01:07, 52.75s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:   1%|▏          | 3/209 [03:30<3:01:07, 52.75s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:   2%|▏          | 4/209 [03:30<2:58:38, 52.28s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:   2%|▏          | 4/209 [04:21<2:58:38, 52.28s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:   2%|▎          | 5/209 [04:21<2:55:37, 51.65s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:   2%|▎          | 5/209 [05:11<2:55:37, 51.65s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:   3%|▎          | 6/209 [05:11<2:52:29, 50.98s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:   3%|▎          | 6/209 [06:00<2:52:29, 50.98s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 1:   3%|▎          | 7/209 [06:00<2:49:55, 50.47s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 1:   3%|▎          | 7/209 [06:51<2:49:55, 50.47s/it, training_loss=0.222]\u001b[A\n",
      "Epoch 1:   4%|▍          | 8/209 [06:51<2:50:04, 50.77s/it, training_loss=0.222]\u001b[A\n",
      "Epoch 1:   4%|▍          | 8/209 [07:52<2:50:04, 50.77s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:   4%|▍          | 9/209 [07:52<2:59:30, 53.85s/it, training_loss=0.240]\u001b[A\n",
      "Epoch 1:   4%|▍          | 9/209 [08:47<2:59:30, 53.85s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 1:   5%|▍         | 10/209 [08:47<2:59:54, 54.24s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 1:   5%|▍         | 10/209 [09:42<2:59:54, 54.24s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:   5%|▌         | 11/209 [09:42<2:59:09, 54.29s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:   5%|▌         | 11/209 [10:33<2:59:09, 54.29s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:   6%|▌         | 12/209 [10:33<2:55:06, 53.33s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:   6%|▌         | 12/209 [11:25<2:55:06, 53.33s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:   6%|▌         | 13/209 [11:25<2:53:29, 53.11s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:   6%|▌         | 13/209 [12:16<2:53:29, 53.11s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:   7%|▋         | 14/209 [12:16<2:50:39, 52.51s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 1:   7%|▋         | 14/209 [13:06<2:50:39, 52.51s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 1:   7%|▋         | 15/209 [13:06<2:47:23, 51.77s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 1:   7%|▋         | 15/209 [13:57<2:47:23, 51.77s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:   8%|▊         | 16/209 [13:57<2:45:13, 51.36s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:   8%|▊         | 16/209 [14:48<2:45:13, 51.36s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:   8%|▊         | 17/209 [14:48<2:44:31, 51.42s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:   8%|▊         | 17/209 [15:38<2:44:31, 51.42s/it, training_loss=0.215]\u001b[A\n",
      "Epoch 1:   9%|▊         | 18/209 [15:38<2:41:40, 50.79s/it, training_loss=0.215]\u001b[A\n",
      "Epoch 1:   9%|▊         | 18/209 [16:28<2:41:40, 50.79s/it, training_loss=0.222]\u001b[A\n",
      "Epoch 1:   9%|▉         | 19/209 [16:28<2:39:56, 50.51s/it, training_loss=0.222]\u001b[A\n",
      "Epoch 1:   9%|▉         | 19/209 [17:19<2:39:56, 50.51s/it, training_loss=0.217]\u001b[A\n",
      "Epoch 1:  10%|▉         | 20/209 [17:19<2:39:59, 50.79s/it, training_loss=0.217]\u001b[A\n",
      "Epoch 1:  10%|▉         | 20/209 [18:15<2:39:59, 50.79s/it, training_loss=0.206]\u001b[A\n",
      "Epoch 1:  10%|█         | 21/209 [18:15<2:43:42, 52.25s/it, training_loss=0.206]\u001b[A\n",
      "Epoch 1:  10%|█         | 21/209 [19:10<2:43:42, 52.25s/it, training_loss=0.207]\u001b[A\n",
      "Epoch 1:  11%|█         | 22/209 [19:10<2:45:23, 53.07s/it, training_loss=0.207]\u001b[A\n",
      "Epoch 1:  11%|█         | 22/209 [20:06<2:45:23, 53.07s/it, training_loss=0.229]\u001b[A\n",
      "Epoch 1:  11%|█         | 23/209 [20:06<2:47:06, 53.91s/it, training_loss=0.229]\u001b[A\n",
      "Epoch 1:  11%|█         | 23/209 [21:02<2:47:06, 53.91s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 24/209 [21:02<2:48:37, 54.69s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 24/209 [21:57<2:48:37, 54.69s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 25/209 [21:57<2:47:40, 54.68s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 25/209 [22:47<2:47:40, 54.68s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 26/209 [22:47<2:42:35, 53.31s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 26/209 [23:37<2:42:35, 53.31s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 27/209 [23:37<2:38:24, 52.22s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 27/209 [24:28<2:38:24, 52.22s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 28/209 [24:28<2:37:09, 52.10s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 28/209 [25:18<2:37:09, 52.10s/it, training_loss=0.206]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 29/209 [25:18<2:34:31, 51.51s/it, training_loss=0.206]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 29/209 [26:10<2:34:31, 51.51s/it, training_loss=0.200]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 30/209 [26:10<2:33:43, 51.53s/it, training_loss=0.200]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 30/209 [27:00<2:33:43, 51.53s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 31/209 [27:00<2:31:16, 50.99s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 31/209 [27:50<2:31:16, 50.99s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 32/209 [27:50<2:29:57, 50.83s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 32/209 [28:45<2:29:57, 50.83s/it, training_loss=0.197]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 33/209 [28:45<2:32:35, 52.02s/it, training_loss=0.197]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 33/209 [29:40<2:32:35, 52.02s/it, training_loss=0.215]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 34/209 [29:40<2:34:05, 52.83s/it, training_loss=0.215]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 34/209 [30:34<2:34:05, 52.83s/it, training_loss=0.191]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 35/209 [30:34<2:34:05, 53.13s/it, training_loss=0.191]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 35/209 [31:28<2:34:05, 53.13s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 36/209 [31:28<2:34:30, 53.59s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 36/209 [32:23<2:34:30, 53.59s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 37/209 [32:23<2:34:43, 53.97s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 37/209 [33:18<2:34:43, 53.97s/it, training_loss=0.170]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 38/209 [33:18<2:34:55, 54.36s/it, training_loss=0.170]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 38/209 [34:08<2:34:55, 54.36s/it, training_loss=0.190]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 39/209 [34:08<2:30:04, 52.97s/it, training_loss=0.190]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 39/209 [34:58<2:30:04, 52.97s/it, training_loss=0.182]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 40/209 [34:58<2:26:34, 52.04s/it, training_loss=0.182]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 40/209 [35:47<2:26:34, 52.04s/it, training_loss=0.210]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 41/209 [35:47<2:23:18, 51.18s/it, training_loss=0.210]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 41/209 [36:37<2:23:18, 51.18s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  20%|██        | 42/209 [36:37<2:21:09, 50.72s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  20%|██        | 42/209 [37:27<2:21:09, 50.72s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  21%|██        | 43/209 [37:27<2:20:16, 50.70s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  21%|██        | 43/209 [38:17<2:20:16, 50.70s/it, training_loss=0.200]\u001b[A\n",
      "Epoch 1:  21%|██        | 44/209 [38:17<2:18:28, 50.36s/it, training_loss=0.200]\u001b[A\n",
      "Epoch 1:  21%|██        | 44/209 [39:07<2:18:28, 50.36s/it, training_loss=0.177]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 45/209 [39:07<2:17:05, 50.16s/it, training_loss=0.177]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 45/209 [39:58<2:17:05, 50.16s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 46/209 [39:58<2:17:09, 50.49s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 46/209 [40:53<2:17:09, 50.49s/it, training_loss=0.177]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 47/209 [40:53<2:20:05, 51.88s/it, training_loss=0.177]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 47/209 [41:46<2:20:05, 51.88s/it, training_loss=0.204]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  23%|██▎       | 48/209 [41:46<2:20:01, 52.18s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 48/209 [42:41<2:20:01, 52.18s/it, training_loss=0.165]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 49/209 [42:41<2:21:46, 53.17s/it, training_loss=0.165]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 49/209 [45:35<2:21:46, 53.17s/it, training_loss=0.192]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 50/209 [45:35<3:56:18, 89.17s/it, training_loss=0.192]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 50/209 [46:28<3:56:18, 89.17s/it, training_loss=0.190]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 51/209 [46:28<3:26:51, 78.55s/it, training_loss=0.190]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 51/209 [47:17<3:26:51, 78.55s/it, training_loss=0.195]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 52/209 [47:17<3:02:12, 69.63s/it, training_loss=0.195]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 52/209 [48:08<3:02:12, 69.63s/it, training_loss=0.160]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 53/209 [48:08<2:46:01, 63.85s/it, training_loss=0.160]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 53/209 [48:58<2:46:01, 63.85s/it, training_loss=0.176]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 54/209 [48:58<2:34:50, 59.94s/it, training_loss=0.176]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 54/209 [49:48<2:34:50, 59.94s/it, training_loss=0.211]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 55/209 [49:48<2:25:39, 56.75s/it, training_loss=0.211]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 55/209 [50:37<2:25:39, 56.75s/it, training_loss=0.176]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 56/209 [50:37<2:18:54, 54.48s/it, training_loss=0.176]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 56/209 [51:27<2:18:54, 54.48s/it, training_loss=0.182]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 57/209 [51:27<2:14:26, 53.07s/it, training_loss=0.182]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 57/209 [52:17<2:14:26, 53.07s/it, training_loss=0.167]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 58/209 [52:17<2:11:32, 52.27s/it, training_loss=0.167]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 58/209 [53:11<2:11:32, 52.27s/it, training_loss=0.159]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 59/209 [53:11<2:11:49, 52.73s/it, training_loss=0.159]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 59/209 [54:12<2:11:49, 52.73s/it, training_loss=0.184]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 60/209 [54:12<2:17:10, 55.24s/it, training_loss=0.184]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 60/209 [55:08<2:17:10, 55.24s/it, training_loss=0.182]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 61/209 [55:08<2:16:49, 55.47s/it, training_loss=0.182]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 61/209 [56:04<2:16:49, 55.47s/it, training_loss=0.179]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 62/209 [56:04<2:16:24, 55.68s/it, training_loss=0.179]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 62/209 [57:00<2:16:24, 55.68s/it, training_loss=0.151]\u001b[A\n",
      "Epoch 1:  30%|███       | 63/209 [57:00<2:15:55, 55.86s/it, training_loss=0.151]\u001b[A\n",
      "Epoch 1:  30%|███       | 63/209 [57:53<2:15:55, 55.86s/it, training_loss=0.181]\u001b[A\n",
      "Epoch 1:  31%|███       | 64/209 [57:53<2:12:22, 54.78s/it, training_loss=0.181]\u001b[A\n",
      "Epoch 1:  31%|███       | 64/209 [58:44<2:12:22, 54.78s/it, training_loss=0.134]\u001b[A\n",
      "Epoch 1:  31%|███       | 65/209 [58:44<2:08:52, 53.70s/it, training_loss=0.134]\u001b[A\n",
      "Epoch 1:  31%|███       | 65/209 [59:33<2:08:52, 53.70s/it, training_loss=0.151]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 66/209 [59:33<2:04:59, 52.45s/it, training_loss=0.151]\u001b[A\n",
      "Epoch 1:  32%|██▌     | 66/209 [1:00:23<2:04:59, 52.45s/it, training_loss=0.134]\u001b[A\n",
      "Epoch 1:  32%|██▌     | 67/209 [1:00:23<2:02:12, 51.64s/it, training_loss=0.134]\u001b[A\n",
      "Epoch 1:  32%|██▌     | 67/209 [1:01:15<2:02:12, 51.64s/it, training_loss=0.154]\u001b[A\n",
      "Epoch 1:  33%|██▌     | 68/209 [1:01:15<2:01:32, 51.72s/it, training_loss=0.154]\u001b[A\n",
      "Epoch 1:  33%|██▌     | 68/209 [1:02:05<2:01:32, 51.72s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  33%|██▋     | 69/209 [1:02:05<1:59:28, 51.21s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  33%|██▋     | 69/209 [1:02:58<1:59:28, 51.21s/it, training_loss=0.164]\u001b[A\n",
      "Epoch 1:  33%|██▋     | 70/209 [1:02:58<2:00:05, 51.84s/it, training_loss=0.164]\u001b[A\n",
      "Epoch 1:  33%|██▋     | 70/209 [1:03:52<2:00:05, 51.84s/it, training_loss=0.169]\u001b[A\n",
      "Epoch 1:  34%|██▋     | 71/209 [1:03:52<2:00:18, 52.31s/it, training_loss=0.169]\u001b[A\n",
      "Epoch 1:  34%|██▋     | 71/209 [1:04:46<2:00:18, 52.31s/it, training_loss=0.154]\u001b[A\n",
      "Epoch 1:  34%|██▊     | 72/209 [1:04:46<2:00:49, 52.92s/it, training_loss=0.154]\u001b[A\n",
      "Epoch 1:  34%|██▊     | 72/209 [1:06:29<2:00:49, 52.92s/it, training_loss=0.151]\u001b[A\n",
      "Epoch 1:  35%|██▊     | 73/209 [1:06:29<2:33:39, 67.79s/it, training_loss=0.151]\u001b[A\n",
      "Epoch 1:  35%|██▊     | 73/209 [1:07:24<2:33:39, 67.79s/it, training_loss=0.153]\u001b[A\n",
      "Epoch 1:  35%|██▊     | 74/209 [1:07:24<2:24:20, 64.15s/it, training_loss=0.153]\u001b[A\n",
      "Epoch 1:  35%|██▊     | 74/209 [1:08:20<2:24:20, 64.15s/it, training_loss=0.128]\u001b[A\n",
      "Epoch 1:  36%|██▊     | 75/209 [1:08:20<2:17:57, 61.78s/it, training_loss=0.128]\u001b[A\n",
      "Epoch 1:  36%|██▊     | 75/209 [1:09:15<2:17:57, 61.78s/it, training_loss=0.149]\u001b[A\n",
      "Epoch 1:  36%|██▉     | 76/209 [1:09:15<2:12:06, 59.60s/it, training_loss=0.149]\u001b[A\n",
      "Epoch 1:  36%|██▉     | 76/209 [1:10:05<2:12:06, 59.60s/it, training_loss=0.114]\u001b[A\n",
      "Epoch 1:  37%|██▉     | 77/209 [1:10:05<2:04:58, 56.81s/it, training_loss=0.114]\u001b[A\n",
      "Epoch 1:  37%|██▉     | 77/209 [1:10:56<2:04:58, 56.81s/it, training_loss=0.130]\u001b[A\n",
      "Epoch 1:  37%|██▉     | 78/209 [1:10:56<1:59:47, 54.86s/it, training_loss=0.130]\u001b[A\n",
      "Epoch 1:  37%|██▉     | 78/209 [1:11:45<1:59:47, 54.86s/it, training_loss=0.131]\u001b[A\n",
      "Epoch 1:  38%|███     | 79/209 [1:11:45<1:55:27, 53.29s/it, training_loss=0.131]\u001b[A\n",
      "Epoch 1:  38%|███     | 79/209 [1:12:35<1:55:27, 53.29s/it, training_loss=0.211]\u001b[A\n",
      "Epoch 1:  38%|███     | 80/209 [1:12:35<1:52:19, 52.25s/it, training_loss=0.211]\u001b[A\n",
      "Epoch 1:  38%|███     | 80/209 [1:13:26<1:52:19, 52.25s/it, training_loss=0.144]\u001b[A\n",
      "Epoch 1:  39%|███     | 81/209 [1:13:26<1:50:22, 51.74s/it, training_loss=0.144]\u001b[A\n",
      "Epoch 1:  39%|███     | 81/209 [1:14:15<1:50:22, 51.74s/it, training_loss=0.152]\u001b[A\n",
      "Epoch 1:  39%|███▏    | 82/209 [1:14:15<1:48:00, 51.03s/it, training_loss=0.152]\u001b[A\n",
      "Epoch 1:  39%|███▏    | 82/209 [1:15:07<1:48:00, 51.03s/it, training_loss=0.149]\u001b[A\n",
      "Epoch 1:  40%|███▏    | 83/209 [1:15:07<1:47:40, 51.28s/it, training_loss=0.149]\u001b[A\n",
      "Epoch 1:  40%|███▏    | 83/209 [1:16:02<1:47:40, 51.28s/it, training_loss=0.151]\u001b[A\n",
      "Epoch 1:  40%|███▏    | 84/209 [1:16:02<1:49:04, 52.36s/it, training_loss=0.151]\u001b[A\n",
      "Epoch 1:  40%|███▏    | 84/209 [1:16:55<1:49:04, 52.36s/it, training_loss=0.140]\u001b[A\n",
      "Epoch 1:  41%|███▎    | 85/209 [1:16:55<1:48:50, 52.67s/it, training_loss=0.140]\u001b[A\n",
      "Epoch 1:  41%|███▎    | 85/209 [1:17:49<1:48:50, 52.67s/it, training_loss=0.159]\u001b[A\n",
      "Epoch 1:  41%|███▎    | 86/209 [1:17:49<1:48:32, 52.95s/it, training_loss=0.159]\u001b[A\n",
      "Epoch 1:  41%|███▎    | 86/209 [1:18:43<1:48:32, 52.95s/it, training_loss=0.156]\u001b[A\n",
      "Epoch 1:  42%|███▎    | 87/209 [1:18:43<1:48:25, 53.33s/it, training_loss=0.156]\u001b[A\n",
      "Epoch 1:  42%|███▎    | 87/209 [1:19:34<1:48:25, 53.33s/it, training_loss=0.108]\u001b[A\n",
      "Epoch 1:  42%|███▎    | 88/209 [1:19:34<1:46:16, 52.70s/it, training_loss=0.108]\u001b[A\n",
      "Epoch 1:  42%|███▎    | 88/209 [1:20:23<1:46:16, 52.70s/it, training_loss=0.108]\u001b[A\n",
      "Epoch 1:  43%|███▍    | 89/209 [1:20:23<1:43:21, 51.68s/it, training_loss=0.108]\u001b[A\n",
      "Epoch 1:  43%|███▍    | 89/209 [1:21:13<1:43:21, 51.68s/it, training_loss=0.147]\u001b[A\n",
      "Epoch 1:  43%|███▍    | 90/209 [1:21:13<1:41:18, 51.08s/it, training_loss=0.147]\u001b[A\n",
      "Epoch 1:  43%|███▍    | 90/209 [1:22:02<1:41:18, 51.08s/it, training_loss=0.166]\u001b[A\n",
      "Epoch 1:  44%|███▍    | 91/209 [1:22:02<1:39:21, 50.52s/it, training_loss=0.166]\u001b[A\n",
      "Epoch 1:  44%|███▍    | 91/209 [1:22:52<1:39:21, 50.52s/it, training_loss=0.074]\u001b[A\n",
      "Epoch 1:  44%|███▌    | 92/209 [1:22:52<1:38:01, 50.27s/it, training_loss=0.074]\u001b[A\n",
      "Epoch 1:  44%|███▌    | 92/209 [1:23:42<1:38:01, 50.27s/it, training_loss=0.135]\u001b[A\n",
      "Epoch 1:  44%|███▌    | 93/209 [1:23:42<1:37:12, 50.28s/it, training_loss=0.135]\u001b[A\n",
      "Epoch 1:  44%|███▌    | 93/209 [1:24:39<1:37:12, 50.28s/it, training_loss=0.138]\u001b[A\n",
      "Epoch 1:  45%|███▌    | 94/209 [1:24:39<1:40:01, 52.18s/it, training_loss=0.138]\u001b[A\n",
      "Epoch 1:  45%|███▌    | 94/209 [1:25:32<1:40:01, 52.18s/it, training_loss=0.167]\u001b[A\n",
      "Epoch 1:  45%|███▋    | 95/209 [1:25:32<1:39:48, 52.53s/it, training_loss=0.167]\u001b[A\n",
      "Epoch 1:  45%|███▋    | 95/209 [1:26:27<1:39:48, 52.53s/it, training_loss=0.099]\u001b[A\n",
      "Epoch 1:  46%|███▋    | 96/209 [1:26:27<1:40:10, 53.19s/it, training_loss=0.099]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  46%|███▋    | 96/209 [1:27:22<1:40:10, 53.19s/it, training_loss=0.127]\u001b[A\n",
      "Epoch 1:  46%|███▋    | 97/209 [1:27:22<1:40:02, 53.60s/it, training_loss=0.127]\u001b[A\n",
      "Epoch 1:  46%|███▋    | 97/209 [1:28:19<1:40:02, 53.60s/it, training_loss=0.128]\u001b[A\n",
      "Epoch 1:  47%|███▊    | 98/209 [1:28:19<1:41:13, 54.72s/it, training_loss=0.128]\u001b[A\n",
      "Epoch 1:  47%|███▊    | 98/209 [1:29:13<1:41:13, 54.72s/it, training_loss=0.125]\u001b[A\n",
      "Epoch 1:  47%|███▊    | 99/209 [1:29:13<1:39:54, 54.49s/it, training_loss=0.125]\u001b[A\n",
      "Epoch 1:  47%|███▊    | 99/209 [1:30:08<1:39:54, 54.49s/it, training_loss=0.108]\u001b[A\n",
      "Epoch 1:  48%|███▎   | 100/209 [1:30:08<1:39:15, 54.64s/it, training_loss=0.108]\u001b[A\n",
      "Epoch 1:  48%|███▎   | 100/209 [1:31:01<1:39:15, 54.64s/it, training_loss=0.165]\u001b[A\n",
      "Epoch 1:  48%|███▍   | 101/209 [1:31:01<1:37:16, 54.04s/it, training_loss=0.165]\u001b[A\n",
      "Epoch 1:  48%|███▍   | 101/209 [1:31:50<1:37:16, 54.04s/it, training_loss=0.112]\u001b[A\n",
      "Epoch 1:  49%|███▍   | 102/209 [1:31:50<1:33:51, 52.63s/it, training_loss=0.112]\u001b[A\n",
      "Epoch 1:  49%|███▍   | 102/209 [1:32:39<1:33:51, 52.63s/it, training_loss=0.143]\u001b[A\n",
      "Epoch 1:  49%|███▍   | 103/209 [1:32:39<1:31:06, 51.57s/it, training_loss=0.143]\u001b[A\n",
      "Epoch 1:  49%|███▍   | 103/209 [1:33:31<1:31:06, 51.57s/it, training_loss=0.119]\u001b[A\n",
      "Epoch 1:  50%|███▍   | 104/209 [1:33:31<1:30:26, 51.68s/it, training_loss=0.119]\u001b[A\n",
      "Epoch 1:  50%|███▍   | 104/209 [1:34:21<1:30:26, 51.68s/it, training_loss=0.116]\u001b[A\n",
      "Epoch 1:  50%|███▌   | 105/209 [1:34:21<1:28:53, 51.29s/it, training_loss=0.116]\u001b[A\n",
      "Epoch 1:  50%|███▌   | 105/209 [1:35:12<1:28:53, 51.29s/it, training_loss=0.109]\u001b[A\n",
      "Epoch 1:  51%|███▌   | 106/209 [1:35:12<1:27:46, 51.13s/it, training_loss=0.109]\u001b[A\n",
      "Epoch 1:  51%|███▌   | 106/209 [1:36:06<1:27:46, 51.13s/it, training_loss=0.097]\u001b[A\n",
      "Epoch 1:  51%|███▌   | 107/209 [1:36:06<1:28:12, 51.89s/it, training_loss=0.097]\u001b[A\n",
      "Epoch 1:  51%|███▌   | 107/209 [1:37:06<1:28:12, 51.89s/it, training_loss=0.160]\u001b[A\n",
      "Epoch 1:  52%|███▌   | 108/209 [1:37:06<1:31:35, 54.41s/it, training_loss=0.160]\u001b[A\n",
      "Epoch 1:  52%|███▌   | 108/209 [1:38:07<1:31:35, 54.41s/it, training_loss=0.095]\u001b[A\n",
      "Epoch 1:  52%|███▋   | 109/209 [1:38:07<1:34:06, 56.47s/it, training_loss=0.095]\u001b[A\n",
      "Epoch 1:  52%|███▋   | 109/209 [1:39:09<1:34:06, 56.47s/it, training_loss=0.093]\u001b[A\n",
      "Epoch 1:  53%|███▋   | 110/209 [1:39:09<1:35:47, 58.05s/it, training_loss=0.093]\u001b[A\n",
      "Epoch 1:  53%|███▋   | 110/209 [1:40:09<1:35:47, 58.05s/it, training_loss=0.120]\u001b[A\n",
      "Epoch 1:  53%|███▋   | 111/209 [1:40:09<1:35:53, 58.71s/it, training_loss=0.120]\u001b[A\n",
      "Epoch 1:  53%|███▋   | 111/209 [1:41:07<1:35:53, 58.71s/it, training_loss=0.126]\u001b[A\n",
      "Epoch 1:  54%|███▊   | 112/209 [1:41:07<1:34:25, 58.41s/it, training_loss=0.126]\u001b[A\n",
      "Epoch 1:  54%|███▊   | 112/209 [1:42:00<1:34:25, 58.41s/it, training_loss=0.131]\u001b[A\n",
      "Epoch 1:  54%|███▊   | 113/209 [1:42:00<1:30:45, 56.72s/it, training_loss=0.131]\u001b[A\n",
      "Epoch 1:  54%|███▊   | 113/209 [1:42:56<1:30:45, 56.72s/it, training_loss=0.089]\u001b[A\n",
      "Epoch 1:  55%|███▊   | 114/209 [1:42:56<1:29:35, 56.58s/it, training_loss=0.089]\u001b[A\n",
      "Epoch 1:  55%|███▊   | 114/209 [1:43:51<1:29:35, 56.58s/it, training_loss=0.149]\u001b[A\n",
      "Epoch 1:  55%|███▊   | 115/209 [1:43:51<1:27:51, 56.08s/it, training_loss=0.149]\u001b[A\n",
      "Epoch 1:  55%|███▊   | 115/209 [1:44:47<1:27:51, 56.08s/it, training_loss=0.104]\u001b[A\n",
      "Epoch 1:  56%|███▉   | 116/209 [1:44:47<1:26:42, 55.94s/it, training_loss=0.104]\u001b[A\n",
      "Epoch 1:  56%|███▉   | 116/209 [1:45:37<1:26:42, 55.94s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 1:  56%|███▉   | 117/209 [1:45:37<1:23:28, 54.44s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 1:  56%|███▉   | 117/209 [1:46:30<1:23:28, 54.44s/it, training_loss=0.098]\u001b[A\n",
      "Epoch 1:  56%|███▉   | 118/209 [1:46:30<1:21:45, 53.91s/it, training_loss=0.098]\u001b[A\n",
      "Epoch 1:  56%|███▉   | 118/209 [1:47:22<1:21:45, 53.91s/it, training_loss=0.129]\u001b[A\n",
      "Epoch 1:  57%|███▉   | 119/209 [1:47:22<1:20:02, 53.36s/it, training_loss=0.129]\u001b[A\n",
      "Epoch 1:  57%|███▉   | 119/209 [1:48:18<1:20:02, 53.36s/it, training_loss=0.109]\u001b[A\n",
      "Epoch 1:  57%|████   | 120/209 [1:48:18<1:20:04, 53.98s/it, training_loss=0.109]\u001b[A\n",
      "Epoch 1:  57%|████   | 120/209 [1:49:15<1:20:04, 53.98s/it, training_loss=0.148]\u001b[A\n",
      "Epoch 1:  58%|████   | 121/209 [1:49:15<1:20:37, 54.98s/it, training_loss=0.148]\u001b[A\n",
      "Epoch 1:  58%|████   | 121/209 [1:50:09<1:20:37, 54.98s/it, training_loss=0.073]\u001b[A\n",
      "Epoch 1:  58%|████   | 122/209 [1:50:09<1:19:23, 54.75s/it, training_loss=0.073]\u001b[A\n",
      "Epoch 1:  58%|████   | 122/209 [1:51:04<1:19:23, 54.75s/it, training_loss=0.127]\u001b[A\n",
      "Epoch 1:  59%|████   | 123/209 [1:51:04<1:18:24, 54.71s/it, training_loss=0.127]\u001b[A\n",
      "Epoch 1:  59%|████   | 123/209 [1:51:59<1:18:24, 54.71s/it, training_loss=0.089]\u001b[A\n",
      "Epoch 1:  59%|████▏  | 124/209 [1:51:59<1:17:32, 54.74s/it, training_loss=0.089]\u001b[A\n",
      "Epoch 1:  59%|████▏  | 124/209 [1:52:48<1:17:32, 54.74s/it, training_loss=0.128]\u001b[A\n",
      "Epoch 1:  60%|████▏  | 125/209 [1:52:48<1:14:33, 53.26s/it, training_loss=0.128]\u001b[A\n",
      "Epoch 1:  60%|████▏  | 125/209 [1:53:40<1:14:33, 53.26s/it, training_loss=0.165]\u001b[A\n",
      "Epoch 1:  60%|████▏  | 126/209 [1:53:40<1:12:57, 52.74s/it, training_loss=0.165]\u001b[A\n",
      "Epoch 1:  60%|████▏  | 126/209 [1:54:30<1:12:57, 52.74s/it, training_loss=0.125]\u001b[A\n",
      "Epoch 1:  61%|████▎  | 127/209 [1:54:30<1:11:11, 52.09s/it, training_loss=0.125]\u001b[A\n",
      "Epoch 1:  61%|████▎  | 127/209 [1:55:28<1:11:11, 52.09s/it, training_loss=0.095]\u001b[A\n",
      "Epoch 1:  61%|████▎  | 128/209 [1:55:28<1:12:25, 53.65s/it, training_loss=0.095]\u001b[A\n",
      "Epoch 1:  61%|████▎  | 128/209 [1:56:18<1:12:25, 53.65s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 1:  62%|████▎  | 129/209 [1:56:18<1:10:20, 52.76s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 1:  62%|████▎  | 129/209 [1:57:08<1:10:20, 52.76s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 1:  62%|████▎  | 130/209 [1:57:08<1:08:14, 51.83s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 1:  62%|████▎  | 130/209 [1:57:59<1:08:14, 51.83s/it, training_loss=0.124]\u001b[A\n",
      "Epoch 1:  63%|████▍  | 131/209 [1:57:59<1:07:10, 51.68s/it, training_loss=0.124]\u001b[A\n",
      "Epoch 1:  63%|████▍  | 131/209 [1:58:56<1:07:10, 51.68s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 1:  63%|████▍  | 132/209 [1:58:56<1:08:16, 53.21s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 1:  63%|████▍  | 132/209 [1:59:51<1:08:16, 53.21s/it, training_loss=0.111]\u001b[A\n",
      "Epoch 1:  64%|████▍  | 133/209 [1:59:51<1:08:03, 53.73s/it, training_loss=0.111]\u001b[A\n",
      "Epoch 1:  64%|████▍  | 133/209 [2:00:47<1:08:03, 53.73s/it, training_loss=0.114]\u001b[A\n",
      "Epoch 1:  64%|████▍  | 134/209 [2:00:47<1:08:08, 54.51s/it, training_loss=0.114]\u001b[A\n",
      "Epoch 1:  64%|████▍  | 134/209 [2:01:44<1:08:08, 54.51s/it, training_loss=0.127]\u001b[A\n",
      "Epoch 1:  65%|████▌  | 135/209 [2:01:44<1:07:50, 55.00s/it, training_loss=0.127]\u001b[A\n",
      "Epoch 1:  65%|████▌  | 135/209 [2:02:43<1:07:50, 55.00s/it, training_loss=0.086]\u001b[A\n",
      "Epoch 1:  65%|████▌  | 136/209 [2:02:43<1:08:21, 56.18s/it, training_loss=0.086]\u001b[A\n",
      "Epoch 1:  65%|████▌  | 136/209 [2:03:34<1:08:21, 56.18s/it, training_loss=0.094]\u001b[A\n",
      "Epoch 1:  66%|████▌  | 137/209 [2:03:34<1:05:48, 54.84s/it, training_loss=0.094]\u001b[A\n",
      "Epoch 1:  66%|████▌  | 137/209 [2:04:25<1:05:48, 54.84s/it, training_loss=0.097]\u001b[A\n",
      "Epoch 1:  66%|████▌  | 138/209 [2:04:25<1:03:15, 53.46s/it, training_loss=0.097]\u001b[A\n",
      "Epoch 1:  66%|████▌  | 138/209 [2:05:15<1:03:15, 53.46s/it, training_loss=0.129]\u001b[A\n",
      "Epoch 1:  67%|████▋  | 139/209 [2:05:15<1:01:19, 52.56s/it, training_loss=0.129]\u001b[A\n",
      "Epoch 1:  67%|████▋  | 139/209 [2:06:06<1:01:19, 52.56s/it, training_loss=0.163]\u001b[A\n",
      "Epoch 1:  67%|██████   | 140/209 [2:06:06<59:59, 52.16s/it, training_loss=0.163]\u001b[A\n",
      "Epoch 1:  67%|██████   | 140/209 [2:07:00<59:59, 52.16s/it, training_loss=0.099]\u001b[A\n",
      "Epoch 1:  67%|██████   | 141/209 [2:07:00<59:31, 52.52s/it, training_loss=0.099]\u001b[A\n",
      "Epoch 1:  67%|██████   | 141/209 [2:07:52<59:31, 52.52s/it, training_loss=0.112]\u001b[A\n",
      "Epoch 1:  68%|██████   | 142/209 [2:07:52<58:30, 52.39s/it, training_loss=0.112]\u001b[A\n",
      "Epoch 1:  68%|██████   | 142/209 [2:08:43<58:30, 52.39s/it, training_loss=0.087]\u001b[A\n",
      "Epoch 1:  68%|██████▏  | 143/209 [2:08:43<57:08, 51.94s/it, training_loss=0.087]\u001b[A\n",
      "Epoch 1:  68%|██████▏  | 143/209 [2:09:37<57:08, 51.94s/it, training_loss=0.092]\u001b[A\n",
      "Epoch 1:  69%|██████▏  | 144/209 [2:09:37<57:12, 52.81s/it, training_loss=0.092]\u001b[A\n",
      "Epoch 1:  69%|██████▏  | 144/209 [2:10:52<57:12, 52.81s/it, training_loss=0.055]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  69%|████▊  | 145/209 [2:10:52<1:03:20, 59.38s/it, training_loss=0.055]\u001b[A\n",
      "Epoch 1:  69%|████▊  | 145/209 [2:11:48<1:03:20, 59.38s/it, training_loss=0.131]\u001b[A\n",
      "Epoch 1:  70%|████▉  | 146/209 [2:11:48<1:01:24, 58.49s/it, training_loss=0.131]\u001b[A\n",
      "Epoch 1:  70%|████▉  | 146/209 [2:12:45<1:01:24, 58.49s/it, training_loss=0.182]\u001b[A\n",
      "Epoch 1:  70%|██████▎  | 147/209 [2:12:45<59:53, 57.97s/it, training_loss=0.182]\u001b[A\n",
      "Epoch 1:  70%|██████▎  | 147/209 [2:13:43<59:53, 57.97s/it, training_loss=0.103]\u001b[A\n",
      "Epoch 1:  71%|██████▎  | 148/209 [2:13:43<58:46, 57.81s/it, training_loss=0.103]\u001b[A\n",
      "Epoch 1:  71%|██████▎  | 148/209 [2:14:36<58:46, 57.81s/it, training_loss=0.092]\u001b[A\n",
      "Epoch 1:  71%|██████▍  | 149/209 [2:14:36<56:30, 56.52s/it, training_loss=0.092]\u001b[A\n",
      "Epoch 1:  71%|██████▍  | 149/209 [2:15:27<56:30, 56.52s/it, training_loss=0.093]\u001b[A\n",
      "Epoch 1:  72%|██████▍  | 150/209 [2:15:27<53:48, 54.72s/it, training_loss=0.093]\u001b[A\n",
      "Epoch 1:  72%|██████▍  | 150/209 [2:16:19<53:48, 54.72s/it, training_loss=0.130]\u001b[A\n",
      "Epoch 1:  72%|██████▌  | 151/209 [2:16:19<52:08, 53.93s/it, training_loss=0.130]\u001b[A\n",
      "Epoch 1:  72%|██████▌  | 151/209 [2:17:12<52:08, 53.93s/it, training_loss=0.101]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 152/209 [2:17:12<51:03, 53.75s/it, training_loss=0.101]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 152/209 [2:18:05<51:03, 53.75s/it, training_loss=0.087]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 153/209 [2:18:05<50:00, 53.58s/it, training_loss=0.087]\u001b[A\n",
      "Epoch 1:  73%|██████▌  | 153/209 [2:18:58<50:00, 53.58s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 154/209 [2:18:58<48:53, 53.34s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 154/209 [2:19:52<48:53, 53.34s/it, training_loss=0.094]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 155/209 [2:19:52<48:11, 53.54s/it, training_loss=0.094]\u001b[A\n",
      "Epoch 1:  74%|██████▋  | 155/209 [2:20:48<48:11, 53.54s/it, training_loss=0.082]\u001b[A\n",
      "Epoch 1:  75%|██████▋  | 156/209 [2:20:48<48:02, 54.39s/it, training_loss=0.082]\u001b[A\n",
      "Epoch 1:  75%|██████▋  | 156/209 [2:21:45<48:02, 54.39s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 1:  75%|██████▊  | 157/209 [2:21:45<47:41, 55.03s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 1:  75%|██████▊  | 157/209 [2:22:44<47:41, 55.03s/it, training_loss=0.065]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 158/209 [2:22:44<47:53, 56.34s/it, training_loss=0.065]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 158/209 [2:23:43<47:53, 56.34s/it, training_loss=0.115]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 159/209 [2:23:43<47:35, 57.11s/it, training_loss=0.115]\u001b[A\n",
      "Epoch 1:  76%|██████▊  | 159/209 [2:24:38<47:35, 57.11s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 160/209 [2:24:38<45:55, 56.24s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 160/209 [2:25:29<45:55, 56.24s/it, training_loss=0.093]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 161/209 [2:25:29<43:54, 54.89s/it, training_loss=0.093]\u001b[A\n",
      "Epoch 1:  77%|██████▉  | 161/209 [2:26:21<43:54, 54.89s/it, training_loss=0.089]\u001b[A\n",
      "Epoch 1:  78%|██████▉  | 162/209 [2:26:21<42:15, 53.95s/it, training_loss=0.089]\u001b[A\n",
      "Epoch 1:  78%|██████▉  | 162/209 [2:27:12<42:15, 53.95s/it, training_loss=0.099]\u001b[A\n",
      "Epoch 1:  78%|███████  | 163/209 [2:27:12<40:47, 53.21s/it, training_loss=0.099]\u001b[A\n",
      "Epoch 1:  78%|███████  | 163/209 [2:28:06<40:47, 53.21s/it, training_loss=0.084]\u001b[A\n",
      "Epoch 1:  78%|███████  | 164/209 [2:28:06<39:59, 53.31s/it, training_loss=0.084]\u001b[A\n",
      "Epoch 1:  78%|███████  | 164/209 [2:28:58<39:59, 53.31s/it, training_loss=0.138]\u001b[A\n",
      "Epoch 1:  79%|███████  | 165/209 [2:28:58<38:41, 52.77s/it, training_loss=0.138]\u001b[A\n",
      "Epoch 1:  79%|███████  | 165/209 [2:29:49<38:41, 52.77s/it, training_loss=0.091]\u001b[A\n",
      "Epoch 1:  79%|███████▏ | 166/209 [2:29:49<37:36, 52.49s/it, training_loss=0.091]\u001b[A\n",
      "Epoch 1:  79%|███████▏ | 166/209 [2:30:43<37:36, 52.49s/it, training_loss=0.117]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 167/209 [2:30:43<36:52, 52.69s/it, training_loss=0.117]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 167/209 [2:31:39<36:52, 52.69s/it, training_loss=0.117]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 168/209 [2:31:39<36:50, 53.90s/it, training_loss=0.117]\u001b[A\n",
      "Epoch 1:  80%|███████▏ | 168/209 [2:32:35<36:50, 53.90s/it, training_loss=0.092]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 169/209 [2:32:35<36:13, 54.35s/it, training_loss=0.092]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 169/209 [2:33:31<36:13, 54.35s/it, training_loss=0.226]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 170/209 [2:33:31<35:47, 55.06s/it, training_loss=0.226]\u001b[A\n",
      "Epoch 1:  81%|███████▎ | 170/209 [2:34:26<35:47, 55.06s/it, training_loss=0.109]\u001b[A\n",
      "Epoch 1:  82%|███████▎ | 171/209 [2:34:26<34:43, 54.82s/it, training_loss=0.109]\u001b[A\n",
      "Epoch 1:  82%|███████▎ | 171/209 [2:35:20<34:43, 54.82s/it, training_loss=0.118]\u001b[A\n",
      "Epoch 1:  82%|███████▍ | 172/209 [2:35:20<33:47, 54.81s/it, training_loss=0.118]\u001b[A\n",
      "Epoch 1:  82%|███████▍ | 172/209 [2:36:09<33:47, 54.81s/it, training_loss=0.109]\u001b[A\n",
      "Epoch 1:  83%|███████▍ | 173/209 [2:36:09<31:50, 53.08s/it, training_loss=0.109]\u001b[A\n",
      "Epoch 1:  83%|███████▍ | 173/209 [2:36:59<31:50, 53.08s/it, training_loss=0.115]\u001b[A\n",
      "Epoch 1:  83%|███████▍ | 174/209 [2:36:59<30:18, 51.97s/it, training_loss=0.115]\u001b[A\n",
      "Epoch 1:  83%|███████▍ | 174/209 [2:37:48<30:18, 51.97s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 175/209 [2:37:48<28:54, 51.03s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 175/209 [2:38:40<28:54, 51.03s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 176/209 [2:38:41<28:21, 51.57s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 1:  84%|███████▌ | 176/209 [2:39:33<28:21, 51.57s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 1:  85%|███████▌ | 177/209 [2:39:33<27:38, 51.82s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 1:  85%|███████▌ | 177/209 [2:40:23<27:38, 51.82s/it, training_loss=0.091]\u001b[A\n",
      "Epoch 1:  85%|███████▋ | 178/209 [2:40:23<26:28, 51.25s/it, training_loss=0.091]\u001b[A\n",
      "Epoch 1:  85%|███████▋ | 178/209 [2:41:14<26:28, 51.25s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 1:  86%|███████▋ | 179/209 [2:41:14<25:37, 51.24s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 1:  86%|███████▋ | 179/209 [2:42:06<25:37, 51.24s/it, training_loss=0.071]\u001b[A\n",
      "Epoch 1:  86%|███████▊ | 180/209 [2:42:06<24:56, 51.59s/it, training_loss=0.071]\u001b[A\n",
      "Epoch 1:  86%|███████▊ | 180/209 [2:43:02<24:56, 51.59s/it, training_loss=0.063]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 181/209 [2:43:02<24:41, 52.92s/it, training_loss=0.063]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 181/209 [2:43:57<24:41, 52.92s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 182/209 [2:43:57<24:01, 53.38s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 1:  87%|███████▊ | 182/209 [2:44:52<24:01, 53.38s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 183/209 [2:44:52<23:23, 53.99s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 183/209 [2:45:47<23:23, 53.99s/it, training_loss=0.118]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 184/209 [2:45:47<22:34, 54.19s/it, training_loss=0.118]\u001b[A\n",
      "Epoch 1:  88%|███████▉ | 184/209 [2:46:39<22:34, 54.19s/it, training_loss=0.121]\u001b[A\n",
      "Epoch 1:  89%|███████▉ | 185/209 [2:46:39<21:26, 53.62s/it, training_loss=0.121]\u001b[A\n",
      "Epoch 1:  89%|███████▉ | 185/209 [2:47:29<21:26, 53.62s/it, training_loss=0.125]\u001b[A\n",
      "Epoch 1:  89%|████████ | 186/209 [2:47:29<20:07, 52.49s/it, training_loss=0.125]\u001b[A\n",
      "Epoch 1:  89%|████████ | 186/209 [2:48:19<20:07, 52.49s/it, training_loss=0.128]\u001b[A\n",
      "Epoch 1:  89%|████████ | 187/209 [2:48:19<18:55, 51.62s/it, training_loss=0.128]\u001b[A\n",
      "Epoch 1:  89%|████████ | 187/209 [2:49:09<18:55, 51.62s/it, training_loss=0.078]\u001b[A\n",
      "Epoch 1:  90%|████████ | 188/209 [2:49:09<17:58, 51.34s/it, training_loss=0.078]\u001b[A\n",
      "Epoch 1:  90%|████████ | 188/209 [2:50:02<17:58, 51.34s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 1:  90%|████████▏| 189/209 [2:50:02<17:15, 51.75s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 1:  90%|████████▏| 189/209 [2:50:54<17:15, 51.75s/it, training_loss=0.112]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 190/209 [2:50:54<16:23, 51.76s/it, training_loss=0.112]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 190/209 [2:51:44<16:23, 51.76s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 191/209 [2:51:44<15:20, 51.13s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 1:  91%|████████▏| 191/209 [2:52:35<15:20, 51.13s/it, training_loss=0.082]\u001b[A\n",
      "Epoch 1:  92%|████████▎| 192/209 [2:52:35<14:30, 51.23s/it, training_loss=0.082]\u001b[A\n",
      "Epoch 1:  92%|████████▎| 192/209 [2:53:32<14:30, 51.23s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 1:  92%|████████▎| 193/209 [2:53:32<14:07, 52.99s/it, training_loss=0.040]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  92%|████████▎| 193/209 [2:54:28<14:07, 52.99s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 1:  93%|████████▎| 194/209 [2:54:28<13:25, 53.71s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 1:  93%|████████▎| 194/209 [2:55:30<13:25, 53.71s/it, training_loss=0.058]\u001b[A\n",
      "Epoch 1:  93%|████████▍| 195/209 [2:55:30<13:07, 56.22s/it, training_loss=0.058]\u001b[A\n",
      "Epoch 1:  93%|████████▍| 195/209 [2:56:27<13:07, 56.22s/it, training_loss=0.109]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 196/209 [2:56:27<12:16, 56.69s/it, training_loss=0.109]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 196/209 [2:57:21<12:16, 56.69s/it, training_loss=0.094]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 197/209 [2:57:21<11:10, 55.91s/it, training_loss=0.094]\u001b[A\n",
      "Epoch 1:  94%|████████▍| 197/209 [2:58:12<11:10, 55.91s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 198/209 [2:58:12<09:56, 54.21s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 198/209 [2:59:04<09:56, 54.21s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 199/209 [2:59:04<08:57, 53.77s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 1:  95%|████████▌| 199/209 [2:59:54<08:57, 53.77s/it, training_loss=0.126]\u001b[A\n",
      "Epoch 1:  96%|████████▌| 200/209 [2:59:54<07:53, 52.64s/it, training_loss=0.126]\u001b[A\n",
      "Epoch 1:  96%|████████▌| 200/209 [3:00:43<07:53, 52.64s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 1:  96%|████████▋| 201/209 [3:00:43<06:52, 51.51s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 1:  96%|████████▋| 201/209 [3:01:34<06:52, 51.51s/it, training_loss=0.071]\u001b[A\n",
      "Epoch 1:  97%|████████▋| 202/209 [3:01:34<05:58, 51.25s/it, training_loss=0.071]\u001b[A\n",
      "Epoch 1:  97%|████████▋| 202/209 [3:02:25<05:58, 51.25s/it, training_loss=0.137]\u001b[A\n",
      "Epoch 1:  97%|████████▋| 203/209 [3:02:25<05:07, 51.22s/it, training_loss=0.137]\u001b[A\n",
      "Epoch 1:  97%|████████▋| 203/209 [3:03:16<05:07, 51.22s/it, training_loss=0.129]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 204/209 [3:03:16<04:15, 51.06s/it, training_loss=0.129]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 204/209 [3:04:11<04:15, 51.06s/it, training_loss=0.140]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 205/209 [3:04:11<03:28, 52.20s/it, training_loss=0.140]\u001b[A\n",
      "Epoch 1:  98%|████████▊| 205/209 [3:05:07<03:28, 52.20s/it, training_loss=0.079]\u001b[A\n",
      "Epoch 1:  99%|████████▊| 206/209 [3:05:07<02:40, 53.57s/it, training_loss=0.079]\u001b[A\n",
      "Epoch 1:  99%|████████▊| 206/209 [3:06:03<02:40, 53.57s/it, training_loss=0.149]\u001b[A\n",
      "Epoch 1:  99%|████████▉| 207/209 [3:06:03<01:48, 54.26s/it, training_loss=0.149]\u001b[A\n",
      "Epoch 1:  99%|████████▉| 207/209 [3:07:01<01:48, 54.26s/it, training_loss=0.074]\u001b[A\n",
      "Epoch 1: 100%|████████▉| 208/209 [3:07:01<00:55, 55.28s/it, training_loss=0.074]\u001b[A\n",
      "Epoch 1: 100%|████████▉| 208/209 [3:07:17<00:55, 55.28s/it, training_loss=0.086]\u001b[A\n",
      "Epoch 1: 100%|█████████| 209/209 [3:07:17<00:00, 43.48s/it, training_loss=0.086]\u001b[A\n",
      "  0%|                                                   | 0/3 [3:07:18<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 0.42449829189115734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▊                                           | 1/53 [00:07<06:45,  7.81s/it]\u001b[A\n",
      "  4%|█▋                                          | 2/53 [00:15<06:33,  7.71s/it]\u001b[A\n",
      "  6%|██▍                                         | 3/53 [00:23<06:33,  7.86s/it]\u001b[A\n",
      "  8%|███▎                                        | 4/53 [00:31<06:25,  7.86s/it]\u001b[A\n",
      "  9%|████▏                                       | 5/53 [00:39<06:14,  7.79s/it]\u001b[A\n",
      " 11%|████▉                                       | 6/53 [00:47<06:09,  7.87s/it]\u001b[A\n",
      " 13%|█████▊                                      | 7/53 [00:54<05:57,  7.78s/it]\u001b[A\n",
      " 15%|██████▋                                     | 8/53 [01:02<05:48,  7.74s/it]\u001b[A\n",
      " 17%|███████▍                                    | 9/53 [01:09<05:39,  7.72s/it]\u001b[A\n",
      " 19%|████████                                   | 10/53 [01:17<05:32,  7.72s/it]\u001b[A\n",
      " 21%|████████▉                                  | 11/53 [01:25<05:23,  7.71s/it]\u001b[A\n",
      " 23%|█████████▋                                 | 12/53 [01:33<05:15,  7.70s/it]\u001b[A\n",
      " 25%|██████████▌                                | 13/53 [01:40<05:07,  7.69s/it]\u001b[A\n",
      " 26%|███████████▎                               | 14/53 [01:48<04:59,  7.68s/it]\u001b[A\n",
      " 28%|████████████▏                              | 15/53 [01:56<04:52,  7.69s/it]\u001b[A\n",
      " 30%|████████████▉                              | 16/53 [02:03<04:44,  7.70s/it]\u001b[A\n",
      " 32%|█████████████▊                             | 17/53 [02:11<04:37,  7.71s/it]\u001b[A\n",
      " 34%|██████████████▌                            | 18/53 [02:19<04:30,  7.72s/it]\u001b[A\n",
      " 36%|███████████████▍                           | 19/53 [02:27<04:23,  7.74s/it]\u001b[A\n",
      " 38%|████████████████▏                          | 20/53 [02:35<04:18,  7.82s/it]\u001b[A\n",
      " 40%|█████████████████                          | 21/53 [02:42<04:10,  7.83s/it]\u001b[A\n",
      " 42%|█████████████████▊                         | 22/53 [02:50<04:03,  7.84s/it]\u001b[A\n",
      " 43%|██████████████████▋                        | 23/53 [02:58<03:55,  7.87s/it]\u001b[A\n",
      " 45%|███████████████████▍                       | 24/53 [03:06<03:48,  7.88s/it]\u001b[A\n",
      " 47%|████████████████████▎                      | 25/53 [03:14<03:39,  7.85s/it]\u001b[A\n",
      " 49%|█████████████████████                      | 26/53 [03:22<03:31,  7.84s/it]\u001b[A\n",
      " 51%|█████████████████████▉                     | 27/53 [03:30<03:23,  7.84s/it]\u001b[A\n",
      " 53%|██████████████████████▋                    | 28/53 [03:37<03:15,  7.80s/it]\u001b[A\n",
      " 55%|███████████████████████▌                   | 29/53 [03:45<03:06,  7.78s/it]\u001b[A\n",
      " 57%|████████████████████████▎                  | 30/53 [03:53<02:58,  7.77s/it]\u001b[A\n",
      " 58%|█████████████████████████▏                 | 31/53 [04:01<02:50,  7.77s/it]\u001b[A\n",
      " 60%|█████████████████████████▉                 | 32/53 [04:08<02:43,  7.77s/it]\u001b[A\n",
      " 62%|██████████████████████████▊                | 33/53 [04:16<02:35,  7.77s/it]\u001b[A\n",
      " 64%|███████████████████████████▌               | 34/53 [04:24<02:27,  7.77s/it]\u001b[A\n",
      " 66%|████████████████████████████▍              | 35/53 [04:32<02:19,  7.78s/it]\u001b[A\n",
      " 68%|█████████████████████████████▏             | 36/53 [04:40<02:13,  7.84s/it]\u001b[A\n",
      " 70%|██████████████████████████████             | 37/53 [04:48<02:09,  8.08s/it]\u001b[A\n",
      " 72%|██████████████████████████████▊            | 38/53 [04:56<02:01,  8.07s/it]\u001b[A\n",
      " 74%|███████████████████████████████▋           | 39/53 [05:04<01:52,  8.05s/it]\u001b[A\n",
      " 75%|████████████████████████████████▍          | 40/53 [05:12<01:44,  8.01s/it]\u001b[A\n",
      " 77%|█████████████████████████████████▎         | 41/53 [05:20<01:36,  8.02s/it]\u001b[A\n",
      " 79%|██████████████████████████████████         | 42/53 [05:28<01:27,  8.00s/it]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 43/53 [05:36<01:20,  8.01s/it]\u001b[A\n",
      " 83%|███████████████████████████████████▋       | 44/53 [05:44<01:12,  8.04s/it]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 45/53 [05:52<01:04,  8.00s/it]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 46/53 [06:00<00:56,  8.02s/it]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 47/53 [06:09<00:49,  8.17s/it]\u001b[A\n",
      " 91%|██████████████████████████████████████▉    | 48/53 [06:18<00:41,  8.34s/it]\u001b[A\n",
      " 92%|███████████████████████████████████████▊   | 49/53 [06:26<00:33,  8.43s/it]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 50/53 [06:35<00:25,  8.50s/it]\u001b[A\n",
      " 96%|█████████████████████████████████████████▍ | 51/53 [06:43<00:16,  8.41s/it]\u001b[A\n",
      " 98%|██████████████████████████████████████████▏| 52/53 [06:51<00:08,  8.38s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████| 53/53 [06:52<00:00,  7.79s/it]\u001b[A\n",
      " 33%|████████████▋                         | 1/3 [3:14:11<6:28:22, 11651.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.2428572193350432\n",
      "F1 Score (Weighted): 0.9044577623612672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2:   0%|                                          | 0/209 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:   0%|                     | 0/209 [00:54<?, ?it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 2:   0%|           | 1/209 [00:54<3:09:26, 54.65s/it, training_loss=0.091]\u001b[A\n",
      "Epoch 2:   0%|           | 1/209 [01:56<3:09:26, 54.65s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 2:   1%|           | 2/209 [01:56<3:23:43, 59.05s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 2:   1%|           | 2/209 [02:50<3:23:43, 59.05s/it, training_loss=0.072]\u001b[A\n",
      "Epoch 2:   1%|▏          | 3/209 [02:50<3:13:55, 56.48s/it, training_loss=0.072]\u001b[A\n",
      "Epoch 2:   1%|▏          | 3/209 [03:44<3:13:55, 56.48s/it, training_loss=0.095]\u001b[A\n",
      "Epoch 2:   2%|▏          | 4/209 [03:44<3:09:32, 55.48s/it, training_loss=0.095]\u001b[A\n",
      "Epoch 2:   2%|▏          | 4/209 [04:37<3:09:32, 55.48s/it, training_loss=0.078]\u001b[A\n",
      "Epoch 2:   2%|▎          | 5/209 [04:37<3:05:59, 54.70s/it, training_loss=0.078]\u001b[A\n",
      "Epoch 2:   2%|▎          | 5/209 [05:27<3:05:59, 54.70s/it, training_loss=0.140]\u001b[A\n",
      "Epoch 2:   3%|▎          | 6/209 [05:27<3:00:12, 53.26s/it, training_loss=0.140]\u001b[A\n",
      "Epoch 2:   3%|▎          | 6/209 [06:19<3:00:12, 53.26s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 2:   3%|▎          | 7/209 [06:19<2:57:22, 52.69s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 2:   3%|▎          | 7/209 [07:14<2:57:22, 52.69s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 2:   4%|▍          | 8/209 [07:14<2:59:27, 53.57s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 2:   4%|▍          | 8/209 [08:11<2:59:27, 53.57s/it, training_loss=0.106]\u001b[A\n",
      "Epoch 2:   4%|▍          | 9/209 [08:11<3:01:33, 54.47s/it, training_loss=0.106]\u001b[A\n",
      "Epoch 2:   4%|▍          | 9/209 [09:07<3:01:33, 54.47s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 2:   5%|▍         | 10/209 [09:07<3:02:30, 55.03s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 2:   5%|▍         | 10/209 [10:05<3:02:30, 55.03s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 2:   5%|▌         | 11/209 [10:05<3:04:00, 55.76s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 2:   5%|▌         | 11/209 [10:58<3:04:00, 55.76s/it, training_loss=0.092]\u001b[A\n",
      "Epoch 2:   6%|▌         | 12/209 [10:58<3:00:55, 55.10s/it, training_loss=0.092]\u001b[A\n",
      "Epoch 2:   6%|▌         | 12/209 [11:49<3:00:55, 55.10s/it, training_loss=0.077]\u001b[A\n",
      "Epoch 2:   6%|▌         | 13/209 [11:49<2:55:30, 53.73s/it, training_loss=0.077]\u001b[A\n",
      "Epoch 2:   6%|▌         | 13/209 [12:41<2:55:30, 53.73s/it, training_loss=0.102]\u001b[A\n",
      "Epoch 2:   7%|▋         | 14/209 [12:41<2:53:31, 53.39s/it, training_loss=0.102]\u001b[A\n",
      "Epoch 2:   7%|▋         | 14/209 [13:31<2:53:31, 53.39s/it, training_loss=0.100]\u001b[A\n",
      "Epoch 2:   7%|▋         | 15/209 [13:31<2:49:20, 52.38s/it, training_loss=0.100]\u001b[A\n",
      "Epoch 2:   7%|▋         | 15/209 [14:20<2:49:20, 52.38s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 2:   8%|▊         | 16/209 [14:20<2:45:20, 51.40s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 2:   8%|▊         | 16/209 [15:11<2:45:20, 51.40s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 2:   8%|▊         | 17/209 [15:11<2:44:06, 51.29s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 2:   8%|▊         | 17/209 [16:03<2:44:06, 51.29s/it, training_loss=0.058]\u001b[A\n",
      "Epoch 2:   9%|▊         | 18/209 [16:03<2:43:21, 51.32s/it, training_loss=0.058]\u001b[A\n",
      "Epoch 2:   9%|▊         | 18/209 [16:53<2:43:21, 51.32s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 2:   9%|▉         | 19/209 [16:53<2:41:01, 50.85s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 2:   9%|▉         | 19/209 [17:46<2:41:01, 50.85s/it, training_loss=0.068]\u001b[A\n",
      "Epoch 2:  10%|▉         | 20/209 [17:46<2:42:18, 51.53s/it, training_loss=0.068]\u001b[A\n",
      "Epoch 2:  10%|▉         | 20/209 [18:40<2:42:18, 51.53s/it, training_loss=0.071]\u001b[A\n",
      "Epoch 2:  10%|█         | 21/209 [18:40<2:43:47, 52.28s/it, training_loss=0.071]\u001b[A\n",
      "Epoch 2:  10%|█         | 21/209 [19:37<2:43:47, 52.28s/it, training_loss=0.116]\u001b[A\n",
      "Epoch 2:  11%|█         | 22/209 [19:37<2:47:39, 53.79s/it, training_loss=0.116]\u001b[A\n",
      "Epoch 2:  11%|█         | 22/209 [20:32<2:47:39, 53.79s/it, training_loss=0.096]\u001b[A\n",
      "Epoch 2:  11%|█         | 23/209 [20:32<2:47:32, 54.05s/it, training_loss=0.096]\u001b[A\n",
      "Epoch 2:  11%|█         | 23/209 [21:25<2:47:32, 54.05s/it, training_loss=0.045]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 24/209 [21:25<2:45:37, 53.72s/it, training_loss=0.045]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 24/209 [22:17<2:45:37, 53.72s/it, training_loss=0.089]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 25/209 [22:17<2:43:10, 53.21s/it, training_loss=0.089]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 25/209 [23:09<2:43:10, 53.21s/it, training_loss=0.123]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 26/209 [23:09<2:41:15, 52.87s/it, training_loss=0.123]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 26/209 [24:00<2:41:15, 52.87s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 27/209 [24:00<2:38:37, 52.30s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 27/209 [24:56<2:38:37, 52.30s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 28/209 [24:56<2:41:41, 53.60s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 28/209 [25:49<2:41:41, 53.60s/it, training_loss=0.079]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 29/209 [25:49<2:39:44, 53.24s/it, training_loss=0.079]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 29/209 [26:41<2:39:44, 53.24s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 30/209 [26:41<2:38:14, 53.04s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 30/209 [27:36<2:38:14, 53.04s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 31/209 [27:36<2:39:00, 53.60s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 31/209 [28:28<2:39:00, 53.60s/it, training_loss=0.077]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 32/209 [28:28<2:36:01, 52.89s/it, training_loss=0.077]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 32/209 [29:22<2:36:01, 52.89s/it, training_loss=0.115]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 33/209 [29:22<2:36:35, 53.38s/it, training_loss=0.115]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 33/209 [30:19<2:36:35, 53.38s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  16%|█▋        | 34/209 [30:19<2:38:41, 54.41s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  16%|█▋        | 34/209 [31:18<2:38:41, 54.41s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 35/209 [31:18<2:41:30, 55.69s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 35/209 [32:14<2:41:30, 55.69s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 36/209 [32:14<2:41:04, 55.87s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 36/209 [33:05<2:41:04, 55.87s/it, training_loss=0.084]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 37/209 [33:05<2:36:22, 54.55s/it, training_loss=0.084]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 37/209 [33:56<2:36:22, 54.55s/it, training_loss=0.072]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 38/209 [33:56<2:31:56, 53.31s/it, training_loss=0.072]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 38/209 [34:45<2:31:56, 53.31s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 2:  19%|█▊        | 39/209 [34:45<2:27:48, 52.17s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 2:  19%|█▊        | 39/209 [35:35<2:27:48, 52.17s/it, training_loss=0.051]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 40/209 [35:35<2:25:16, 51.58s/it, training_loss=0.051]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 40/209 [36:25<2:25:16, 51.58s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 41/209 [36:25<2:22:58, 51.06s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 41/209 [37:15<2:22:58, 51.06s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 2:  20%|██        | 42/209 [37:15<2:20:54, 50.62s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 2:  20%|██        | 42/209 [38:14<2:20:54, 50.62s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 2:  21%|██        | 43/209 [38:14<2:27:09, 53.19s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 2:  21%|██        | 43/209 [39:05<2:27:09, 53.19s/it, training_loss=0.108]\u001b[A\n",
      "Epoch 2:  21%|██        | 44/209 [39:05<2:24:35, 52.58s/it, training_loss=0.108]\u001b[A\n",
      "Epoch 2:  21%|██        | 44/209 [40:02<2:24:35, 52.58s/it, training_loss=0.095]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 45/209 [40:02<2:27:02, 53.79s/it, training_loss=0.095]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 45/209 [40:58<2:27:02, 53.79s/it, training_loss=0.148]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 46/209 [40:58<2:27:55, 54.45s/it, training_loss=0.148]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 46/209 [41:53<2:27:55, 54.45s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 47/209 [41:53<2:27:16, 54.54s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 47/209 [42:48<2:27:16, 54.54s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 48/209 [42:48<2:27:26, 54.94s/it, training_loss=0.105]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  23%|██▎       | 48/209 [43:42<2:27:26, 54.94s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 49/209 [43:42<2:25:35, 54.60s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 49/209 [44:37<2:25:35, 54.60s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 50/209 [44:37<2:25:00, 54.72s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 50/209 [45:28<2:25:00, 54.72s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 51/209 [45:28<2:20:51, 53.49s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 51/209 [46:20<2:20:51, 53.49s/it, training_loss=0.089]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 52/209 [46:20<2:19:10, 53.19s/it, training_loss=0.089]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 52/209 [47:11<2:19:10, 53.19s/it, training_loss=0.041]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 53/209 [47:11<2:16:21, 52.45s/it, training_loss=0.041]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 53/209 [48:01<2:16:21, 52.45s/it, training_loss=0.069]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 54/209 [48:01<2:13:34, 51.71s/it, training_loss=0.069]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 54/209 [48:51<2:13:34, 51.71s/it, training_loss=0.089]\u001b[A\n",
      "Epoch 2:  26%|██▋       | 55/209 [48:51<2:11:03, 51.06s/it, training_loss=0.089]\u001b[A\n",
      "Epoch 2:  26%|██▋       | 55/209 [49:41<2:11:03, 51.06s/it, training_loss=0.089]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 56/209 [49:41<2:09:46, 50.89s/it, training_loss=0.089]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 56/209 [50:42<2:09:46, 50.89s/it, training_loss=0.063]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 57/209 [50:42<2:16:11, 53.76s/it, training_loss=0.063]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 57/209 [51:37<2:16:11, 53.76s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 58/209 [51:37<2:16:43, 54.33s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 58/209 [53:39<2:16:43, 54.33s/it, training_loss=0.102]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 59/209 [53:39<3:06:04, 74.43s/it, training_loss=0.102]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 59/209 [54:35<3:06:04, 74.43s/it, training_loss=0.096]\u001b[A\n",
      "Epoch 2:  29%|██▊       | 60/209 [54:35<2:51:34, 69.09s/it, training_loss=0.096]\u001b[A\n",
      "Epoch 2:  29%|██▊       | 60/209 [55:28<2:51:34, 69.09s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 61/209 [55:28<2:38:14, 64.15s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 61/209 [56:18<2:38:14, 64.15s/it, training_loss=0.119]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 62/209 [56:18<2:26:53, 59.95s/it, training_loss=0.119]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 62/209 [57:09<2:26:53, 59.95s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 2:  30%|███       | 63/209 [57:09<2:19:02, 57.14s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 2:  30%|███       | 63/209 [58:00<2:19:02, 57.14s/it, training_loss=0.031]\u001b[A\n",
      "Epoch 2:  31%|███       | 64/209 [58:00<2:13:49, 55.38s/it, training_loss=0.031]\u001b[A\n",
      "Epoch 2:  31%|███       | 64/209 [58:55<2:13:49, 55.38s/it, training_loss=0.113]\u001b[A\n",
      "Epoch 2:  31%|███       | 65/209 [58:55<2:13:05, 55.45s/it, training_loss=0.113]\u001b[A\n",
      "Epoch 2:  31%|███       | 65/209 [59:47<2:13:05, 55.45s/it, training_loss=0.188]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 66/209 [59:47<2:09:37, 54.39s/it, training_loss=0.188]\u001b[A\n",
      "Epoch 2:  32%|██▌     | 66/209 [1:00:38<2:09:37, 54.39s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 2:  32%|██▌     | 67/209 [1:00:38<2:06:10, 53.32s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 2:  32%|██▌     | 67/209 [1:02:25<2:06:10, 53.32s/it, training_loss=0.074]\u001b[A\n",
      "Epoch 2:  33%|██▌     | 68/209 [1:02:25<2:43:09, 69.43s/it, training_loss=0.074]\u001b[A\n",
      "Epoch 2:  33%|██▌     | 68/209 [1:03:22<2:43:09, 69.43s/it, training_loss=0.092]\u001b[A\n",
      "Epoch 2:  33%|██▋     | 69/209 [1:03:22<2:33:07, 65.63s/it, training_loss=0.092]\u001b[A\n",
      "Epoch 2:  33%|██▋     | 69/209 [1:04:19<2:33:07, 65.63s/it, training_loss=0.022]\u001b[A\n",
      "Epoch 2:  33%|██▋     | 70/209 [1:04:19<2:25:47, 62.93s/it, training_loss=0.022]\u001b[A\n",
      "Epoch 2:  33%|██▋     | 70/209 [1:09:24<2:25:47, 62.93s/it, training_loss=0.106]\u001b[A\n",
      "Epoch 2:  34%|██▍    | 71/209 [1:09:24<5:12:12, 135.74s/it, training_loss=0.106]\u001b[A\n",
      "Epoch 2:  34%|██▍    | 71/209 [1:10:28<5:12:12, 135.74s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 2:  34%|██▍    | 72/209 [1:10:28<4:20:29, 114.09s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 2:  34%|██▍    | 72/209 [1:11:20<4:20:29, 114.09s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 2:  35%|██▊     | 73/209 [1:11:20<3:36:30, 95.52s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 2:  35%|██▊     | 73/209 [1:12:11<3:36:30, 95.52s/it, training_loss=0.103]\u001b[A\n",
      "Epoch 2:  35%|██▊     | 74/209 [1:12:11<3:05:02, 82.24s/it, training_loss=0.103]\u001b[A\n",
      "Epoch 2:  35%|██▊     | 74/209 [1:13:01<3:05:02, 82.24s/it, training_loss=0.080]\u001b[A\n",
      "Epoch 2:  36%|██▊     | 75/209 [1:13:01<2:41:55, 72.50s/it, training_loss=0.080]\u001b[A\n",
      "Epoch 2:  36%|██▊     | 75/209 [1:13:50<2:41:55, 72.50s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 2:  36%|██▉     | 76/209 [1:13:50<2:25:24, 65.60s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 2:  36%|██▉     | 76/209 [1:14:40<2:25:24, 65.60s/it, training_loss=0.082]\u001b[A\n",
      "Epoch 2:  37%|██▉     | 77/209 [1:14:40<2:13:42, 60.78s/it, training_loss=0.082]\u001b[A\n",
      "Epoch 2:  37%|██▉     | 77/209 [1:15:31<2:13:42, 60.78s/it, training_loss=0.108]\u001b[A\n",
      "Epoch 2:  37%|██▉     | 78/209 [1:15:31<2:06:19, 57.86s/it, training_loss=0.108]\u001b[A\n",
      "Epoch 2:  37%|██▉     | 78/209 [1:16:28<2:06:19, 57.86s/it, training_loss=0.077]\u001b[A\n",
      "Epoch 2:  38%|███     | 79/209 [1:16:28<2:05:00, 57.70s/it, training_loss=0.077]\u001b[A\n",
      "Epoch 2:  38%|███     | 79/209 [1:17:25<2:05:00, 57.70s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 2:  38%|███     | 80/209 [1:17:25<2:03:37, 57.50s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 2:  38%|███     | 80/209 [1:33:38<2:03:37, 57.50s/it, training_loss=0.086]\u001b[A\n",
      "Epoch 2:  39%|██▎   | 81/209 [1:33:38<11:48:06, 331.93s/it, training_loss=0.086]\u001b[A\n",
      "Epoch 2:  39%|██▎   | 81/209 [1:34:52<11:48:06, 331.93s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  39%|██▋    | 82/209 [1:34:52<8:58:50, 254.57s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  39%|██▋    | 82/209 [1:35:59<8:58:50, 254.57s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  40%|██▊    | 83/209 [1:35:59<6:56:54, 198.53s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  40%|██▊    | 83/209 [1:37:01<6:56:54, 198.53s/it, training_loss=0.045]\u001b[A\n",
      "Epoch 2:  40%|██▊    | 84/209 [1:37:01<5:27:47, 157.34s/it, training_loss=0.045]\u001b[A\n",
      "Epoch 2:  40%|██▊    | 84/209 [1:38:00<5:27:47, 157.34s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 2:  41%|██▊    | 85/209 [1:38:00<4:24:06, 127.79s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 2:  41%|██▊    | 85/209 [1:39:00<4:24:06, 127.79s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 2:  41%|██▉    | 86/209 [1:39:00<3:40:21, 107.49s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 2:  41%|██▉    | 86/209 [1:39:59<3:40:21, 107.49s/it, training_loss=0.091]\u001b[A\n",
      "Epoch 2:  42%|███▎    | 87/209 [1:39:59<3:09:27, 93.17s/it, training_loss=0.091]\u001b[A\n",
      "Epoch 2:  42%|███▎    | 87/209 [1:42:24<3:09:27, 93.17s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 2:  42%|██▉    | 88/209 [1:42:24<3:39:10, 108.68s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 2:  42%|██▉    | 88/209 [1:43:17<3:39:10, 108.68s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 2:  43%|███▍    | 89/209 [1:43:17<3:03:35, 91.79s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 2:  43%|███▍    | 89/209 [1:44:06<3:03:35, 91.79s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  43%|███▍    | 90/209 [1:44:06<2:36:41, 79.00s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  43%|███▍    | 90/209 [1:44:58<2:36:41, 79.00s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 2:  44%|███▍    | 91/209 [1:44:58<2:19:24, 70.89s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 2:  44%|███▍    | 91/209 [1:45:52<2:19:24, 70.89s/it, training_loss=0.091]\u001b[A\n",
      "Epoch 2:  44%|███▌    | 92/209 [1:45:52<2:08:36, 65.96s/it, training_loss=0.091]\u001b[A\n",
      "Epoch 2:  44%|███▌    | 92/209 [1:46:47<2:08:36, 65.96s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  44%|███▌    | 93/209 [1:46:47<2:00:42, 62.44s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  44%|███▌    | 93/209 [1:47:42<2:00:42, 62.44s/it, training_loss=0.069]\u001b[A\n",
      "Epoch 2:  45%|███▌    | 94/209 [1:47:42<1:55:53, 60.47s/it, training_loss=0.069]\u001b[A\n",
      "Epoch 2:  45%|███▌    | 94/209 [2:04:29<1:55:53, 60.47s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 2:  45%|██▋   | 95/209 [2:04:29<10:54:24, 344.43s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 2:  45%|██▋   | 95/209 [2:05:25<10:54:24, 344.43s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 2:  46%|███▏   | 96/209 [2:05:25<8:05:24, 257.74s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 2:  46%|███▏   | 96/209 [2:06:15<8:05:24, 257.74s/it, training_loss=0.021]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  46%|███▏   | 97/209 [2:06:15<6:05:02, 195.56s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 2:  46%|███▏   | 97/209 [2:07:05<6:05:02, 195.56s/it, training_loss=0.112]\u001b[A\n",
      "Epoch 2:  47%|███▎   | 98/209 [2:07:05<4:40:56, 151.86s/it, training_loss=0.112]\u001b[A\n",
      "Epoch 2:  47%|███▎   | 98/209 [2:07:53<4:40:56, 151.86s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 2:  47%|███▎   | 99/209 [2:07:53<3:41:22, 120.75s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 2:  47%|███▎   | 99/209 [2:08:43<3:41:22, 120.75s/it, training_loss=0.097]\u001b[A\n",
      "Epoch 2:  48%|███▎   | 100/209 [2:08:43<3:00:23, 99.30s/it, training_loss=0.097]\u001b[A\n",
      "Epoch 2:  48%|███▎   | 100/209 [2:09:32<3:00:23, 99.30s/it, training_loss=0.099]\u001b[A\n",
      "Epoch 2:  48%|███▍   | 101/209 [2:09:32<2:31:47, 84.33s/it, training_loss=0.099]\u001b[A\n",
      "Epoch 2:  48%|███▍   | 101/209 [2:10:21<2:31:47, 84.33s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 2:  49%|███▍   | 102/209 [2:10:21<2:11:25, 73.70s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 2:  49%|███▍   | 102/209 [2:11:10<2:11:25, 73.70s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 2:  49%|███▍   | 103/209 [2:11:10<1:57:09, 66.31s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 2:  49%|███▍   | 103/209 [2:12:04<1:57:09, 66.31s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  50%|███▍   | 104/209 [2:12:04<1:49:25, 62.53s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  50%|███▍   | 104/209 [2:12:58<1:49:25, 62.53s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 2:  50%|███▌   | 105/209 [2:12:58<1:44:09, 60.10s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 2:  50%|███▌   | 105/209 [2:13:53<1:44:09, 60.10s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  51%|███▌   | 106/209 [2:13:53<1:40:34, 58.59s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  51%|███▌   | 106/209 [2:14:47<1:40:34, 58.59s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 2:  51%|███▌   | 107/209 [2:14:47<1:36:57, 57.04s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 2:  51%|███▌   | 107/209 [2:15:36<1:36:57, 57.04s/it, training_loss=0.131]\u001b[A\n",
      "Epoch 2:  52%|███▌   | 108/209 [2:15:36<1:32:18, 54.84s/it, training_loss=0.131]\u001b[A\n",
      "Epoch 2:  52%|███▌   | 108/209 [2:16:25<1:32:18, 54.84s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 2:  52%|███▋   | 109/209 [2:16:25<1:28:16, 52.96s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 2:  52%|███▋   | 109/209 [2:17:14<1:28:16, 52.96s/it, training_loss=0.107]\u001b[A\n",
      "Epoch 2:  53%|███▋   | 110/209 [2:17:14<1:25:22, 51.74s/it, training_loss=0.107]\u001b[A\n",
      "Epoch 2:  53%|███▋   | 110/209 [2:18:04<1:25:22, 51.74s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 2:  53%|███▋   | 111/209 [2:18:04<1:23:38, 51.21s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 2:  53%|███▋   | 111/209 [2:18:53<1:23:38, 51.21s/it, training_loss=0.075]\u001b[A\n",
      "Epoch 2:  54%|███▊   | 112/209 [2:18:53<1:21:50, 50.62s/it, training_loss=0.075]\u001b[A\n",
      "Epoch 2:  54%|███▊   | 112/209 [2:19:42<1:21:50, 50.62s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 2:  54%|███▊   | 113/209 [2:19:42<1:20:26, 50.27s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 2:  54%|███▊   | 113/209 [2:20:32<1:20:26, 50.27s/it, training_loss=0.056]\u001b[A\n",
      "Epoch 2:  55%|███▊   | 114/209 [2:20:32<1:19:14, 50.04s/it, training_loss=0.056]\u001b[A\n",
      "Epoch 2:  55%|███▊   | 114/209 [2:21:21<1:19:14, 50.04s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  55%|███▊   | 115/209 [2:21:21<1:18:01, 49.80s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  55%|███▊   | 115/209 [2:22:11<1:18:01, 49.80s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 2:  56%|███▉   | 116/209 [2:22:11<1:17:08, 49.76s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 2:  56%|███▉   | 116/209 [2:23:05<1:17:08, 49.76s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 2:  56%|███▉   | 117/209 [2:23:05<1:18:12, 51.01s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 2:  56%|███▉   | 117/209 [2:23:59<1:18:12, 51.01s/it, training_loss=0.097]\u001b[A\n",
      "Epoch 2:  56%|███▉   | 118/209 [2:23:59<1:18:54, 52.02s/it, training_loss=0.097]\u001b[A\n",
      "Epoch 2:  56%|███▉   | 118/209 [2:24:54<1:18:54, 52.02s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 2:  57%|███▉   | 119/209 [2:24:54<1:19:14, 52.83s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 2:  57%|███▉   | 119/209 [2:25:49<1:19:14, 52.83s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  57%|████   | 120/209 [2:25:49<1:19:12, 53.40s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  57%|████   | 120/209 [2:26:42<1:19:12, 53.40s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  58%|████   | 121/209 [2:26:42<1:18:20, 53.41s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  58%|████   | 121/209 [2:27:33<1:18:20, 53.41s/it, training_loss=0.091]\u001b[A\n",
      "Epoch 2:  58%|████   | 122/209 [2:27:33<1:16:32, 52.79s/it, training_loss=0.091]\u001b[A\n",
      "Epoch 2:  58%|████   | 122/209 [2:28:22<1:16:32, 52.79s/it, training_loss=0.089]\u001b[A\n",
      "Epoch 2:  59%|████   | 123/209 [2:28:22<1:14:04, 51.68s/it, training_loss=0.089]\u001b[A\n",
      "Epoch 2:  59%|████   | 123/209 [2:29:12<1:14:04, 51.68s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 2:  59%|████▏  | 124/209 [2:29:12<1:12:27, 51.15s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 2:  59%|████▏  | 124/209 [2:30:02<1:12:27, 51.15s/it, training_loss=0.051]\u001b[A\n",
      "Epoch 2:  60%|████▏  | 125/209 [2:30:02<1:11:02, 50.75s/it, training_loss=0.051]\u001b[A\n",
      "Epoch 2:  60%|████▏  | 125/209 [2:30:52<1:11:02, 50.75s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 2:  60%|████▏  | 126/209 [2:30:52<1:09:37, 50.34s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 2:  60%|████▏  | 126/209 [2:31:40<1:09:37, 50.34s/it, training_loss=0.139]\u001b[A\n",
      "Epoch 2:  61%|████▎  | 127/209 [2:31:40<1:08:02, 49.79s/it, training_loss=0.139]\u001b[A\n",
      "Epoch 2:  61%|████▎  | 127/209 [2:32:30<1:08:02, 49.79s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 2:  61%|████▎  | 128/209 [2:32:30<1:07:04, 49.68s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 2:  61%|████▎  | 128/209 [2:33:18<1:07:04, 49.68s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 2:  62%|████▎  | 129/209 [2:33:18<1:05:48, 49.35s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 2:  62%|████▎  | 129/209 [2:34:08<1:05:48, 49.35s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  62%|████▎  | 130/209 [2:34:08<1:05:22, 49.65s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  62%|████▎  | 130/209 [2:35:03<1:05:22, 49.65s/it, training_loss=0.041]\u001b[A\n",
      "Epoch 2:  63%|████▍  | 131/209 [2:35:03<1:06:33, 51.20s/it, training_loss=0.041]\u001b[A\n",
      "Epoch 2:  63%|████▍  | 131/209 [2:35:58<1:06:33, 51.20s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 2:  63%|████▍  | 132/209 [2:35:58<1:06:56, 52.17s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 2:  63%|████▍  | 132/209 [2:36:51<1:06:56, 52.17s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 2:  64%|████▍  | 133/209 [2:36:51<1:06:26, 52.46s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 2:  64%|████▍  | 133/209 [2:37:42<1:06:26, 52.46s/it, training_loss=0.032]\u001b[A\n",
      "Epoch 2:  64%|████▍  | 134/209 [2:37:42<1:05:03, 52.05s/it, training_loss=0.032]\u001b[A\n",
      "Epoch 2:  64%|████▍  | 134/209 [2:38:32<1:05:03, 52.05s/it, training_loss=0.084]\u001b[A\n",
      "Epoch 2:  65%|████▌  | 135/209 [2:38:32<1:03:37, 51.58s/it, training_loss=0.084]\u001b[A\n",
      "Epoch 2:  65%|████▌  | 135/209 [2:39:22<1:03:37, 51.58s/it, training_loss=0.092]\u001b[A\n",
      "Epoch 2:  65%|████▌  | 136/209 [2:39:22<1:02:00, 50.96s/it, training_loss=0.092]\u001b[A\n",
      "Epoch 2:  65%|████▌  | 136/209 [2:40:10<1:02:00, 50.96s/it, training_loss=0.091]\u001b[A\n",
      "Epoch 2:  66%|████▌  | 137/209 [2:40:10<1:00:14, 50.20s/it, training_loss=0.091]\u001b[A\n",
      "Epoch 2:  66%|████▌  | 137/209 [2:40:59<1:00:14, 50.20s/it, training_loss=0.072]\u001b[A\n",
      "Epoch 2:  66%|█████▉   | 138/209 [2:40:59<58:53, 49.77s/it, training_loss=0.072]\u001b[A\n",
      "Epoch 2:  66%|█████▉   | 138/209 [2:41:48<58:53, 49.77s/it, training_loss=0.108]\u001b[A\n",
      "Epoch 2:  67%|█████▉   | 139/209 [2:41:48<57:47, 49.54s/it, training_loss=0.108]\u001b[A\n",
      "Epoch 2:  67%|█████▉   | 139/209 [2:42:38<57:47, 49.54s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  67%|██████   | 140/209 [2:42:38<57:04, 49.63s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  67%|██████   | 140/209 [2:43:27<57:04, 49.63s/it, training_loss=0.045]\u001b[A\n",
      "Epoch 2:  67%|██████   | 141/209 [2:43:27<56:09, 49.55s/it, training_loss=0.045]\u001b[A\n",
      "Epoch 2:  67%|██████   | 141/209 [2:44:16<56:09, 49.55s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 2:  68%|██████   | 142/209 [2:44:16<55:11, 49.43s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 2:  68%|██████   | 142/209 [2:45:06<55:11, 49.43s/it, training_loss=0.125]\u001b[A\n",
      "Epoch 2:  68%|██████▏  | 143/209 [2:45:06<54:16, 49.33s/it, training_loss=0.125]\u001b[A\n",
      "Epoch 2:  68%|██████▏  | 143/209 [2:45:58<54:16, 49.33s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 2:  69%|██████▏  | 144/209 [2:45:58<54:36, 50.40s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 2:  69%|██████▏  | 144/209 [2:46:52<54:36, 50.40s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  69%|██████▏  | 145/209 [2:46:52<54:52, 51.45s/it, training_loss=0.040]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  69%|██████▏  | 145/209 [2:47:46<54:52, 51.45s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  70%|██████▎  | 146/209 [2:47:46<54:49, 52.22s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  70%|██████▎  | 146/209 [2:48:41<54:49, 52.22s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 2:  70%|██████▎  | 147/209 [2:48:41<54:41, 52.93s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 2:  70%|██████▎  | 147/209 [2:49:36<54:41, 52.93s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 2:  71%|██████▎  | 148/209 [2:49:36<54:29, 53.60s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 2:  71%|██████▎  | 148/209 [2:50:29<54:29, 53.60s/it, training_loss=0.075]\u001b[A\n",
      "Epoch 2:  71%|██████▍  | 149/209 [2:50:29<53:29, 53.50s/it, training_loss=0.075]\u001b[A\n",
      "Epoch 2:  71%|██████▍  | 149/209 [2:51:18<53:29, 53.50s/it, training_loss=0.125]\u001b[A\n",
      "Epoch 2:  72%|██████▍  | 150/209 [2:51:18<51:17, 52.16s/it, training_loss=0.125]\u001b[A\n",
      "Epoch 2:  72%|██████▍  | 150/209 [2:52:08<51:17, 52.16s/it, training_loss=0.068]\u001b[A\n",
      "Epoch 2:  72%|██████▌  | 151/209 [2:52:08<49:36, 51.31s/it, training_loss=0.068]\u001b[A\n",
      "Epoch 2:  72%|██████▌  | 151/209 [2:52:58<49:36, 51.31s/it, training_loss=0.055]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 152/209 [2:52:58<48:18, 50.85s/it, training_loss=0.055]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 152/209 [2:53:47<48:18, 50.85s/it, training_loss=0.099]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 153/209 [2:53:47<47:08, 50.52s/it, training_loss=0.099]\u001b[A\n",
      "Epoch 2:  73%|██████▌  | 153/209 [2:54:38<47:08, 50.52s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 154/209 [2:54:38<46:13, 50.43s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 154/209 [2:55:27<46:13, 50.43s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 155/209 [2:55:27<45:08, 50.15s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 2:  74%|██████▋  | 155/209 [2:56:16<45:08, 50.15s/it, training_loss=0.097]\u001b[A\n",
      "Epoch 2:  75%|██████▋  | 156/209 [2:56:16<43:53, 49.70s/it, training_loss=0.097]\u001b[A\n",
      "Epoch 2:  75%|██████▋  | 156/209 [2:57:08<43:53, 49.70s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 2:  75%|██████▊  | 157/209 [2:57:08<43:37, 50.35s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 2:  75%|██████▊  | 157/209 [2:58:02<43:37, 50.35s/it, training_loss=0.087]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 158/209 [2:58:02<43:53, 51.63s/it, training_loss=0.087]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 158/209 [2:58:57<43:53, 51.63s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 159/209 [2:58:57<43:49, 52.58s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 2:  76%|██████▊  | 159/209 [2:59:51<43:49, 52.58s/it, training_loss=0.098]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 160/209 [2:59:51<43:19, 53.05s/it, training_loss=0.098]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 160/209 [3:00:45<43:19, 53.05s/it, training_loss=0.065]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 161/209 [3:00:45<42:40, 53.34s/it, training_loss=0.065]\u001b[A\n",
      "Epoch 2:  77%|██████▉  | 161/209 [3:01:40<42:40, 53.34s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  78%|██████▉  | 162/209 [3:01:40<42:03, 53.69s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  78%|██████▉  | 162/209 [3:02:29<42:03, 53.69s/it, training_loss=0.075]\u001b[A\n",
      "Epoch 2:  78%|███████  | 163/209 [3:02:29<40:06, 52.31s/it, training_loss=0.075]\u001b[A\n",
      "Epoch 2:  78%|███████  | 163/209 [3:03:17<40:06, 52.31s/it, training_loss=0.103]\u001b[A\n",
      "Epoch 2:  78%|███████  | 164/209 [3:03:17<38:25, 51.23s/it, training_loss=0.103]\u001b[A\n",
      "Epoch 2:  78%|███████  | 164/209 [3:04:07<38:25, 51.23s/it, training_loss=0.123]\u001b[A\n",
      "Epoch 2:  79%|███████  | 165/209 [3:04:07<37:11, 50.73s/it, training_loss=0.123]\u001b[A\n",
      "Epoch 2:  79%|███████  | 165/209 [3:21:57<37:11, 50.73s/it, training_loss=0.130]\u001b[A\n",
      "Epoch 2:  79%|████▊ | 166/209 [3:21:57<4:15:32, 356.56s/it, training_loss=0.130]\u001b[A\n",
      "Epoch 2:  79%|████▊ | 166/209 [3:22:47<4:15:32, 356.56s/it, training_loss=0.100]\u001b[A\n",
      "Epoch 2:  80%|████▊ | 167/209 [3:22:47<3:05:13, 264.61s/it, training_loss=0.100]\u001b[A\n",
      "Epoch 2:  80%|████▊ | 167/209 [3:23:37<3:05:13, 264.61s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 2:  80%|████▊ | 168/209 [3:23:37<2:16:42, 200.06s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 2:  80%|████▊ | 168/209 [3:24:25<2:16:42, 200.06s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 2:  81%|████▊ | 169/209 [3:24:25<1:43:04, 154.62s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 2:  81%|████▊ | 169/209 [3:25:14<1:43:04, 154.62s/it, training_loss=0.109]\u001b[A\n",
      "Epoch 2:  81%|████▉ | 170/209 [3:25:14<1:19:49, 122.80s/it, training_loss=0.109]\u001b[A\n",
      "Epoch 2:  81%|████▉ | 170/209 [3:26:10<1:19:49, 122.80s/it, training_loss=0.079]\u001b[A\n",
      "Epoch 2:  82%|████▉ | 171/209 [3:26:10<1:05:04, 102.75s/it, training_loss=0.079]\u001b[A\n",
      "Epoch 2:  82%|████▉ | 171/209 [3:27:04<1:05:04, 102.75s/it, training_loss=0.113]\u001b[A\n",
      "Epoch 2:  82%|███████▍ | 172/209 [3:27:04<54:22, 88.17s/it, training_loss=0.113]\u001b[A\n",
      "Epoch 2:  82%|███████▍ | 172/209 [3:28:01<54:22, 88.17s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 2:  83%|███████▍ | 173/209 [3:28:01<47:14, 78.74s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 2:  83%|███████▍ | 173/209 [3:28:55<47:14, 78.74s/it, training_loss=0.091]\u001b[A\n",
      "Epoch 2:  83%|███████▍ | 174/209 [3:28:55<41:34, 71.27s/it, training_loss=0.091]\u001b[A\n",
      "Epoch 2:  83%|███████▍ | 174/209 [3:29:49<41:34, 71.27s/it, training_loss=0.051]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 175/209 [3:29:49<37:28, 66.14s/it, training_loss=0.051]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 175/209 [3:30:39<37:28, 66.14s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 176/209 [3:30:39<33:46, 61.41s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 2:  84%|███████▌ | 176/209 [3:31:28<33:46, 61.41s/it, training_loss=0.058]\u001b[A\n",
      "Epoch 2:  85%|███████▌ | 177/209 [3:31:28<30:44, 57.64s/it, training_loss=0.058]\u001b[A\n",
      "Epoch 2:  85%|███████▌ | 177/209 [3:32:17<30:44, 57.64s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  85%|███████▋ | 178/209 [3:32:17<28:23, 54.94s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  85%|███████▋ | 178/209 [3:33:08<28:23, 54.94s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 2:  86%|███████▋ | 179/209 [3:33:08<26:58, 53.96s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 2:  86%|███████▋ | 179/209 [3:33:59<26:58, 53.96s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 2:  86%|███████▊ | 180/209 [3:33:59<25:34, 52.92s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 2:  86%|███████▊ | 180/209 [3:34:47<25:34, 52.92s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 181/209 [3:34:47<24:04, 51.60s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 181/209 [3:35:37<24:04, 51.60s/it, training_loss=0.054]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 182/209 [3:35:37<22:56, 50.99s/it, training_loss=0.054]\u001b[A\n",
      "Epoch 2:  87%|███████▊ | 182/209 [3:36:26<22:56, 50.99s/it, training_loss=0.080]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 183/209 [3:36:26<21:50, 50.42s/it, training_loss=0.080]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 183/209 [3:37:17<21:50, 50.42s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 184/209 [3:37:17<21:08, 50.74s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 2:  88%|███████▉ | 184/209 [3:38:12<21:08, 50.74s/it, training_loss=0.073]\u001b[A\n",
      "Epoch 2:  89%|███████▉ | 185/209 [3:38:12<20:43, 51.83s/it, training_loss=0.073]\u001b[A\n",
      "Epoch 2:  89%|███████▉ | 185/209 [3:39:06<20:43, 51.83s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 2:  89%|████████ | 186/209 [3:39:06<20:10, 52.62s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 2:  89%|████████ | 186/209 [3:40:01<20:10, 52.62s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 2:  89%|████████ | 187/209 [3:40:01<19:29, 53.14s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 2:  89%|████████ | 187/209 [3:40:52<19:29, 53.14s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 2:  90%|████████ | 188/209 [3:40:52<18:23, 52.54s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 2:  90%|████████ | 188/209 [3:41:41<18:23, 52.54s/it, training_loss=0.042]\u001b[A\n",
      "Epoch 2:  90%|████████▏| 189/209 [3:41:41<17:09, 51.46s/it, training_loss=0.042]\u001b[A\n",
      "Epoch 2:  90%|████████▏| 189/209 [3:42:30<17:09, 51.46s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 190/209 [3:42:30<16:03, 50.73s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 190/209 [3:43:19<16:03, 50.73s/it, training_loss=0.102]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 191/209 [3:43:19<15:03, 50.21s/it, training_loss=0.102]\u001b[A\n",
      "Epoch 2:  91%|████████▏| 191/209 [3:44:08<15:03, 50.21s/it, training_loss=0.094]\u001b[A\n",
      "Epoch 2:  92%|████████▎| 192/209 [3:44:08<14:08, 49.92s/it, training_loss=0.094]\u001b[A\n",
      "Epoch 2:  92%|████████▎| 192/209 [3:44:59<14:08, 49.92s/it, training_loss=0.100]\u001b[A\n",
      "Epoch 2:  92%|████████▎| 193/209 [3:44:59<13:22, 50.14s/it, training_loss=0.100]\u001b[A\n",
      "Epoch 2:  92%|████████▎| 193/209 [3:45:48<13:22, 50.14s/it, training_loss=0.055]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  93%|████████▎| 194/209 [3:45:48<12:28, 49.87s/it, training_loss=0.055]\u001b[A\n",
      "Epoch 2:  93%|████████▎| 194/209 [3:46:36<12:28, 49.87s/it, training_loss=0.035]\u001b[A\n",
      "Epoch 2:  93%|████████▍| 195/209 [3:46:36<11:31, 49.40s/it, training_loss=0.035]\u001b[A\n",
      "Epoch 2:  93%|████████▍| 195/209 [3:47:26<11:31, 49.40s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 196/209 [3:47:26<10:42, 49.43s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 196/209 [3:48:15<10:42, 49.43s/it, training_loss=0.068]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 197/209 [3:48:15<09:52, 49.39s/it, training_loss=0.068]\u001b[A\n",
      "Epoch 2:  94%|████████▍| 197/209 [3:49:09<09:52, 49.39s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 198/209 [3:49:09<09:18, 50.81s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 198/209 [3:50:04<09:18, 50.81s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 199/209 [3:50:04<08:39, 51.93s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 2:  95%|████████▌| 199/209 [3:50:57<08:39, 51.93s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 2:  96%|████████▌| 200/209 [3:50:57<07:52, 52.49s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 2:  96%|████████▌| 200/209 [3:51:51<07:52, 52.49s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 2:  96%|████████▋| 201/209 [3:51:51<07:02, 52.85s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 2:  96%|████████▋| 201/209 [3:52:45<07:02, 52.85s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 2:  97%|████████▋| 202/209 [3:52:45<06:11, 53.07s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 2:  97%|████████▋| 202/209 [3:53:35<06:11, 53.07s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 2:  97%|████████▋| 203/209 [3:53:35<05:14, 52.37s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 2:  97%|████████▋| 203/209 [3:54:25<05:14, 52.37s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 204/209 [3:54:25<04:17, 51.44s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 204/209 [3:55:14<04:17, 51.44s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 205/209 [3:55:14<03:22, 50.72s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 2:  98%|████████▊| 205/209 [3:56:03<03:22, 50.72s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 2:  99%|████████▊| 206/209 [3:56:03<02:30, 50.21s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 2:  99%|████████▊| 206/209 [3:56:52<02:30, 50.21s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  99%|████████▉| 207/209 [3:56:52<01:40, 50.03s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  99%|████████▉| 207/209 [3:57:41<01:40, 50.03s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 2: 100%|████████▉| 208/209 [3:57:41<00:49, 49.68s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 2: 100%|████████▉| 208/209 [3:57:56<00:49, 49.68s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 2: 100%|█████████| 209/209 [3:57:56<00:00, 39.21s/it, training_loss=0.059]\u001b[A\n",
      " 33%|████████████▋                         | 1/3 [7:12:08<6:28:22, 11651.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Training loss: 0.2120625183307098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▊                                           | 1/53 [00:07<06:34,  7.59s/it]\u001b[A\n",
      "  4%|█▋                                          | 2/53 [00:15<06:25,  7.56s/it]\u001b[A\n",
      "  6%|██▍                                         | 3/53 [00:22<06:19,  7.59s/it]\u001b[A\n",
      "  8%|███▎                                        | 4/53 [00:30<06:11,  7.58s/it]\u001b[A\n",
      "  9%|████▏                                       | 5/53 [00:37<06:04,  7.58s/it]\u001b[A\n",
      " 11%|████▉                                       | 6/53 [00:45<05:56,  7.58s/it]\u001b[A\n",
      " 13%|█████▊                                      | 7/53 [00:53<05:48,  7.57s/it]\u001b[A\n",
      " 15%|██████▋                                     | 8/53 [01:00<05:41,  7.59s/it]\u001b[A\n",
      " 17%|███████▍                                    | 9/53 [01:08<05:34,  7.61s/it]\u001b[A\n",
      " 19%|████████                                   | 10/53 [01:15<05:27,  7.61s/it]\u001b[A\n",
      " 21%|████████▉                                  | 11/53 [01:23<05:19,  7.61s/it]\u001b[A\n",
      " 23%|█████████▋                                 | 12/53 [01:31<05:12,  7.62s/it]\u001b[A\n",
      " 25%|██████████▌                                | 13/53 [01:38<05:05,  7.63s/it]\u001b[A\n",
      " 26%|███████████▎                               | 14/53 [01:46<04:58,  7.64s/it]\u001b[A\n",
      " 28%|████████████▏                              | 15/53 [01:54<04:51,  7.66s/it]\u001b[A\n",
      " 30%|████████████▉                              | 16/53 [02:01<04:44,  7.68s/it]\u001b[A\n",
      " 32%|█████████████▊                             | 17/53 [02:09<04:37,  7.71s/it]\u001b[A\n",
      " 34%|██████████████▌                            | 18/53 [02:17<04:30,  7.73s/it]\u001b[A\n",
      " 36%|███████████████▍                           | 19/53 [02:25<04:23,  7.75s/it]\u001b[A\n",
      " 38%|████████████████▏                          | 20/53 [02:33<04:15,  7.76s/it]\u001b[A\n",
      " 40%|█████████████████                          | 21/53 [02:40<04:08,  7.77s/it]\u001b[A\n",
      " 42%|█████████████████▊                         | 22/53 [02:48<04:00,  7.77s/it]\u001b[A\n",
      " 43%|██████████████████▋                        | 23/53 [02:56<03:53,  7.79s/it]\u001b[A\n",
      " 45%|███████████████████▍                       | 24/53 [03:04<03:46,  7.81s/it]\u001b[A\n",
      " 47%|████████████████████▎                      | 25/53 [03:12<03:39,  7.83s/it]\u001b[A\n",
      " 49%|█████████████████████                      | 26/53 [03:20<03:32,  7.86s/it]\u001b[A\n",
      " 51%|█████████████████████▉                     | 27/53 [03:28<03:26,  7.93s/it]\u001b[A\n",
      " 53%|██████████████████████▋                    | 28/53 [03:36<03:20,  8.01s/it]\u001b[A\n",
      " 55%|███████████████████████▌                   | 29/53 [03:44<03:15,  8.13s/it]\u001b[A\n",
      " 57%|████████████████████████▎                  | 30/53 [03:53<03:10,  8.29s/it]\u001b[A\n",
      " 58%|█████████████████████████▏                 | 31/53 [04:02<03:06,  8.49s/it]\u001b[A\n",
      " 60%|█████████████████████████▉                 | 32/53 [04:11<03:03,  8.72s/it]\u001b[A\n",
      " 62%|██████████████████████████▊                | 33/53 [04:21<02:58,  8.95s/it]\u001b[A\n",
      " 64%|███████████████████████████▌               | 34/53 [04:30<02:53,  9.15s/it]\u001b[A\n",
      " 66%|████████████████████████████▍              | 35/53 [04:40<02:47,  9.31s/it]\u001b[A\n",
      " 68%|█████████████████████████████▏             | 36/53 [04:50<02:40,  9.45s/it]\u001b[A\n",
      " 70%|██████████████████████████████             | 37/53 [05:00<02:32,  9.55s/it]\u001b[A\n",
      " 72%|██████████████████████████████▊            | 38/53 [05:09<02:24,  9.60s/it]\u001b[A\n",
      " 74%|███████████████████████████████▋           | 39/53 [05:19<02:14,  9.60s/it]\u001b[A\n",
      " 75%|████████████████████████████████▍          | 40/53 [05:28<02:04,  9.54s/it]\u001b[A\n",
      " 77%|█████████████████████████████████▎         | 41/53 [05:38<01:53,  9.48s/it]\u001b[A\n",
      " 79%|██████████████████████████████████         | 42/53 [05:47<01:42,  9.36s/it]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 43/53 [05:56<01:32,  9.24s/it]\u001b[A\n",
      " 83%|███████████████████████████████████▋       | 44/53 [06:05<01:22,  9.14s/it]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 45/53 [06:13<01:12,  9.04s/it]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 46/53 [06:22<01:02,  8.96s/it]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 47/53 [06:31<00:53,  8.88s/it]\u001b[A\n",
      " 91%|██████████████████████████████████████▉    | 48/53 [06:39<00:43,  8.78s/it]\u001b[A\n",
      " 92%|███████████████████████████████████████▊   | 49/53 [06:48<00:34,  8.72s/it]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 50/53 [06:57<00:26,  8.68s/it]\u001b[A\n",
      " 96%|█████████████████████████████████████████▍ | 51/53 [07:05<00:17,  8.64s/it]\u001b[A\n",
      " 98%|██████████████████████████████████████████▏| 52/53 [07:14<00:08,  8.61s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████| 53/53 [07:14<00:00,  8.21s/it]\u001b[A\n",
      " 67%|█████████████████████████▎            | 2/3 [7:19:23<3:44:11, 13451.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.21118896328053385\n",
      "F1 Score (Weighted): 0.9178040137386667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3:   0%|                                          | 0/209 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:   0%|                     | 0/209 [00:50<?, ?it/s, training_loss=0.086]\u001b[A\n",
      "Epoch 3:   0%|           | 1/209 [00:50<2:55:22, 50.59s/it, training_loss=0.086]\u001b[A\n",
      "Epoch 3:   0%|           | 1/209 [01:39<2:55:22, 50.59s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 3:   1%|           | 2/209 [01:39<2:50:59, 49.56s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 3:   1%|           | 2/209 [02:33<2:50:59, 49.56s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 3:   1%|▏          | 3/209 [02:33<2:57:02, 51.57s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 3:   1%|▏          | 3/209 [03:28<2:57:02, 51.57s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 3:   2%|▏          | 4/209 [03:28<3:01:12, 53.04s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 3:   2%|▏          | 4/209 [04:22<3:01:12, 53.04s/it, training_loss=0.092]\u001b[A\n",
      "Epoch 3:   2%|▎          | 5/209 [04:22<3:01:38, 53.42s/it, training_loss=0.092]\u001b[A\n",
      "Epoch 3:   2%|▎          | 5/209 [05:16<3:01:38, 53.42s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 3:   3%|▎          | 6/209 [05:16<3:01:24, 53.62s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 3:   3%|▎          | 6/209 [06:11<3:01:24, 53.62s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 3:   3%|▎          | 7/209 [06:11<3:01:22, 53.87s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 3:   3%|▎          | 7/209 [07:02<3:01:22, 53.87s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 3:   4%|▍          | 8/209 [07:02<2:57:55, 53.11s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 3:   4%|▍          | 8/209 [07:51<2:57:55, 53.11s/it, training_loss=0.051]\u001b[A\n",
      "Epoch 3:   4%|▍          | 9/209 [07:51<2:52:34, 51.77s/it, training_loss=0.051]\u001b[A\n",
      "Epoch 3:   4%|▍          | 9/209 [08:41<2:52:34, 51.77s/it, training_loss=0.082]\u001b[A\n",
      "Epoch 3:   5%|▍         | 10/209 [08:41<2:49:59, 51.26s/it, training_loss=0.082]\u001b[A\n",
      "Epoch 3:   5%|▍         | 10/209 [09:30<2:49:59, 51.26s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 3:   5%|▌         | 11/209 [09:30<2:46:58, 50.60s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 3:   5%|▌         | 11/209 [10:21<2:46:58, 50.60s/it, training_loss=0.079]\u001b[A\n",
      "Epoch 3:   6%|▌         | 12/209 [10:21<2:45:55, 50.54s/it, training_loss=0.079]\u001b[A\n",
      "Epoch 3:   6%|▌         | 12/209 [11:10<2:45:55, 50.54s/it, training_loss=0.029]\u001b[A\n",
      "Epoch 3:   6%|▌         | 13/209 [11:10<2:43:35, 50.08s/it, training_loss=0.029]\u001b[A\n",
      "Epoch 3:   6%|▌         | 13/209 [12:00<2:43:35, 50.08s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 3:   7%|▋         | 14/209 [12:00<2:42:35, 50.03s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 3:   7%|▋         | 14/209 [12:49<2:42:35, 50.03s/it, training_loss=0.062]\u001b[A\n",
      "Epoch 3:   7%|▋         | 15/209 [12:49<2:40:55, 49.77s/it, training_loss=0.062]\u001b[A\n",
      "Epoch 3:   7%|▋         | 15/209 [13:39<2:40:55, 49.77s/it, training_loss=0.090]\u001b[A\n",
      "Epoch 3:   8%|▊         | 16/209 [13:39<2:40:58, 50.04s/it, training_loss=0.090]\u001b[A\n",
      "Epoch 3:   8%|▊         | 16/209 [14:33<2:40:58, 50.04s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 3:   8%|▊         | 17/209 [14:33<2:44:02, 51.26s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 3:   8%|▊         | 17/209 [15:28<2:44:02, 51.26s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 3:   9%|▊         | 18/209 [15:28<2:45:59, 52.14s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 3:   9%|▊         | 18/209 [16:22<2:45:59, 52.14s/it, training_loss=0.069]\u001b[A\n",
      "Epoch 3:   9%|▉         | 19/209 [16:22<2:47:13, 52.81s/it, training_loss=0.069]\u001b[A\n",
      "Epoch 3:   9%|▉         | 19/209 [34:09<2:47:13, 52.81s/it, training_loss=0.114]\u001b[A\n",
      "Epoch 3:  10%|▊       | 20/209 [34:09<18:45:48, 357.40s/it, training_loss=0.114]\u001b[A\n",
      "Epoch 3:  10%|▊       | 20/209 [35:03<18:45:48, 357.40s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 3:  10%|▊       | 21/209 [35:03<13:53:53, 266.13s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 3:  10%|▊       | 21/209 [35:51<13:53:53, 266.13s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 3:  11%|▊       | 22/209 [35:51<10:25:33, 200.71s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 3:  11%|▊       | 22/209 [36:39<10:25:33, 200.71s/it, training_loss=0.099]\u001b[A\n",
      "Epoch 3:  11%|▉        | 23/209 [36:39<8:00:45, 155.09s/it, training_loss=0.099]\u001b[A\n",
      "Epoch 3:  11%|▉        | 23/209 [37:28<8:00:45, 155.09s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 3:  11%|█        | 24/209 [37:28<6:19:37, 123.12s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 3:  11%|█        | 24/209 [38:17<6:19:37, 123.12s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 3:  12%|█        | 25/209 [38:17<5:08:56, 100.74s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 3:  12%|█        | 25/209 [39:05<5:08:56, 100.74s/it, training_loss=0.082]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 26/209 [39:05<4:19:09, 84.97s/it, training_loss=0.082]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 26/209 [39:54<4:19:09, 84.97s/it, training_loss=0.101]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 27/209 [39:54<3:45:30, 74.34s/it, training_loss=0.101]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 27/209 [40:42<3:45:30, 74.34s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 28/209 [40:42<3:20:20, 66.41s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 28/209 [41:32<3:20:20, 66.41s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 29/209 [41:32<3:04:22, 61.46s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 29/209 [42:28<3:04:22, 61.46s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 30/209 [42:28<2:58:04, 59.69s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 30/209 [43:21<2:58:04, 59.69s/it, training_loss=0.035]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 31/209 [43:21<2:51:14, 57.72s/it, training_loss=0.035]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 31/209 [44:13<2:51:14, 57.72s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 3:  15%|█▌        | 32/209 [44:13<2:45:29, 56.10s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 3:  15%|█▌        | 32/209 [45:08<2:45:29, 56.10s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 33/209 [45:08<2:43:23, 55.70s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 33/209 [46:03<2:43:23, 55.70s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 3:  16%|█▋        | 34/209 [46:03<2:42:00, 55.55s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 3:  16%|█▋        | 34/209 [46:51<2:42:00, 55.55s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 35/209 [46:51<2:34:33, 53.30s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 35/209 [47:41<2:34:33, 53.30s/it, training_loss=0.099]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 36/209 [47:41<2:30:59, 52.37s/it, training_loss=0.099]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 36/209 [48:30<2:30:59, 52.37s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 37/209 [48:30<2:26:51, 51.23s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 37/209 [49:19<2:26:51, 51.23s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 38/209 [49:19<2:24:19, 50.64s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 38/209 [50:08<2:24:19, 50.64s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 3:  19%|█▊        | 39/209 [50:08<2:21:50, 50.06s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 3:  19%|█▊        | 39/209 [50:57<2:21:50, 50.06s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 40/209 [50:57<2:19:54, 49.67s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 40/209 [51:46<2:19:54, 49.67s/it, training_loss=0.068]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 41/209 [51:46<2:18:30, 49.47s/it, training_loss=0.068]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 41/209 [52:34<2:18:30, 49.47s/it, training_loss=0.045]\u001b[A\n",
      "Epoch 3:  20%|██        | 42/209 [52:34<2:16:44, 49.13s/it, training_loss=0.045]\u001b[A\n",
      "Epoch 3:  20%|██        | 42/209 [53:26<2:16:44, 49.13s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 3:  21%|██        | 43/209 [53:26<2:17:56, 49.86s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 3:  21%|██        | 43/209 [54:21<2:17:56, 49.86s/it, training_loss=0.084]\u001b[A\n",
      "Epoch 3:  21%|██        | 44/209 [54:21<2:21:35, 51.49s/it, training_loss=0.084]\u001b[A\n",
      "Epoch 3:  21%|██        | 44/209 [55:15<2:21:35, 51.49s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 45/209 [55:15<2:22:47, 52.24s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 45/209 [56:09<2:22:47, 52.24s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 46/209 [56:09<2:23:50, 52.95s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 46/209 [56:59<2:23:50, 52.95s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 47/209 [56:59<2:20:07, 51.90s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 47/209 [57:47<2:20:07, 51.90s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 48/209 [57:47<2:16:33, 50.89s/it, training_loss=0.081]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  23%|██▎       | 48/209 [58:35<2:16:33, 50.89s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 49/209 [58:35<2:12:55, 49.85s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 49/209 [59:23<2:12:55, 49.85s/it, training_loss=0.104]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 50/209 [59:23<2:11:08, 49.49s/it, training_loss=0.104]\u001b[A\n",
      "Epoch 3:  24%|█▉      | 50/209 [1:00:11<2:11:08, 49.49s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 3:  24%|█▉      | 51/209 [1:00:11<2:08:59, 48.99s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 3:  24%|█▉      | 51/209 [1:01:01<2:08:59, 48.99s/it, training_loss=0.068]\u001b[A\n",
      "Epoch 3:  25%|█▉      | 52/209 [1:01:01<2:08:51, 49.25s/it, training_loss=0.068]\u001b[A\n",
      "Epoch 3:  25%|█▉      | 52/209 [1:01:51<2:08:51, 49.25s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 3:  25%|██      | 53/209 [1:01:51<2:08:18, 49.35s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 3:  25%|██      | 53/209 [1:02:40<2:08:18, 49.35s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 3:  26%|██      | 54/209 [1:02:40<2:07:27, 49.34s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 3:  26%|██      | 54/209 [1:03:29<2:07:27, 49.34s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  26%|██      | 55/209 [1:03:29<2:06:26, 49.26s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  26%|██      | 55/209 [1:04:17<2:06:26, 49.26s/it, training_loss=0.077]\u001b[A\n",
      "Epoch 3:  27%|██▏     | 56/209 [1:04:17<2:04:41, 48.90s/it, training_loss=0.077]\u001b[A\n",
      "Epoch 3:  27%|██▏     | 56/209 [1:05:12<2:04:41, 48.90s/it, training_loss=0.029]\u001b[A\n",
      "Epoch 3:  27%|██▏     | 57/209 [1:05:12<2:08:01, 50.54s/it, training_loss=0.029]\u001b[A\n",
      "Epoch 3:  27%|██▏     | 57/209 [1:06:06<2:08:01, 50.54s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 3:  28%|██▏     | 58/209 [1:06:06<2:10:24, 51.82s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 3:  28%|██▏     | 58/209 [1:07:01<2:10:24, 51.82s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 3:  28%|██▎     | 59/209 [1:07:01<2:11:29, 52.60s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 3:  28%|██▎     | 59/209 [1:08:02<2:11:29, 52.60s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 3:  29%|██▎     | 60/209 [1:08:02<2:17:12, 55.25s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 3:  29%|██▎     | 60/209 [1:08:57<2:17:12, 55.25s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 3:  29%|██▎     | 61/209 [1:08:57<2:16:10, 55.21s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 3:  29%|██▎     | 61/209 [1:09:47<2:16:10, 55.21s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 3:  30%|██▎     | 62/209 [1:09:47<2:11:24, 53.64s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 3:  30%|██▎     | 62/209 [1:10:37<2:11:24, 53.64s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 3:  30%|██▍     | 63/209 [1:10:37<2:07:35, 52.44s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 3:  30%|██▍     | 63/209 [1:16:11<2:07:35, 52.44s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 3:  31%|██▏    | 64/209 [1:16:11<5:30:36, 136.80s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 3:  31%|██▏    | 64/209 [1:17:02<5:30:36, 136.80s/it, training_loss=0.068]\u001b[A\n",
      "Epoch 3:  31%|██▏    | 65/209 [1:17:02<4:26:47, 111.16s/it, training_loss=0.068]\u001b[A\n",
      "Epoch 3:  31%|██▏    | 65/209 [1:17:52<4:26:47, 111.16s/it, training_loss=0.077]\u001b[A\n",
      "Epoch 3:  32%|██▌     | 66/209 [1:17:52<3:40:57, 92.71s/it, training_loss=0.077]\u001b[A\n",
      "Epoch 3:  32%|██▌     | 66/209 [1:18:42<3:40:57, 92.71s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 3:  32%|██▌     | 67/209 [1:18:42<3:09:22, 80.02s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 3:  32%|██▌     | 67/209 [1:22:57<3:09:22, 80.02s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 3:  33%|██▎    | 68/209 [1:22:57<5:11:06, 132.39s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 3:  33%|██▎    | 68/209 [1:23:53<5:11:06, 132.39s/it, training_loss=0.054]\u001b[A\n",
      "Epoch 3:  33%|██▎    | 69/209 [1:23:53<4:15:50, 109.65s/it, training_loss=0.054]\u001b[A\n",
      "Epoch 3:  33%|██▎    | 69/209 [1:24:48<4:15:50, 109.65s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 3:  33%|██▋     | 70/209 [1:24:48<3:36:18, 93.37s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 3:  33%|██▋     | 70/209 [1:25:44<3:36:18, 93.37s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 3:  34%|██▋     | 71/209 [1:25:44<3:08:45, 82.07s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 3:  34%|██▋     | 71/209 [1:26:39<3:08:45, 82.07s/it, training_loss=0.077]\u001b[A\n",
      "Epoch 3:  34%|██▊     | 72/209 [1:26:39<2:48:32, 73.82s/it, training_loss=0.077]\u001b[A\n",
      "Epoch 3:  34%|██▊     | 72/209 [1:27:35<2:48:32, 73.82s/it, training_loss=0.054]\u001b[A\n",
      "Epoch 3:  35%|██▊     | 73/209 [1:27:35<2:35:23, 68.55s/it, training_loss=0.054]\u001b[A\n",
      "Epoch 3:  35%|██▊     | 73/209 [1:28:40<2:35:23, 68.55s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 3:  35%|██▊     | 74/209 [1:28:40<2:31:31, 67.34s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 3:  35%|██▊     | 74/209 [1:29:32<2:31:31, 67.34s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 3:  36%|██▊     | 75/209 [1:29:32<2:20:38, 62.97s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 3:  36%|██▊     | 75/209 [1:30:26<2:20:38, 62.97s/it, training_loss=0.075]\u001b[A\n",
      "Epoch 3:  36%|██▉     | 76/209 [1:30:26<2:13:27, 60.21s/it, training_loss=0.075]\u001b[A\n",
      "Epoch 3:  36%|██▉     | 76/209 [1:31:21<2:13:27, 60.21s/it, training_loss=0.022]\u001b[A\n",
      "Epoch 3:  37%|██▉     | 77/209 [1:31:21<2:08:38, 58.47s/it, training_loss=0.022]\u001b[A\n",
      "Epoch 3:  37%|██▉     | 77/209 [1:32:33<2:08:38, 58.47s/it, training_loss=0.055]\u001b[A\n",
      "Epoch 3:  37%|██▉     | 78/209 [1:32:33<2:16:52, 62.69s/it, training_loss=0.055]\u001b[A\n",
      "Epoch 3:  37%|██▉     | 78/209 [1:33:37<2:16:52, 62.69s/it, training_loss=0.022]\u001b[A\n",
      "Epoch 3:  38%|███     | 79/209 [1:33:37<2:16:55, 63.20s/it, training_loss=0.022]\u001b[A\n",
      "Epoch 3:  38%|███     | 79/209 [1:34:34<2:16:55, 63.20s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 3:  38%|███     | 80/209 [1:34:34<2:11:42, 61.26s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 3:  38%|███     | 80/209 [1:35:30<2:11:42, 61.26s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 3:  39%|███     | 81/209 [1:35:30<2:06:59, 59.53s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 3:  39%|███     | 81/209 [1:36:24<2:06:59, 59.53s/it, training_loss=0.090]\u001b[A\n",
      "Epoch 3:  39%|███▏    | 82/209 [1:36:24<2:02:48, 58.02s/it, training_loss=0.090]\u001b[A\n",
      "Epoch 3:  39%|███▏    | 82/209 [1:37:20<2:02:48, 58.02s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 3:  40%|███▏    | 83/209 [1:37:20<2:00:46, 57.51s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 3:  40%|███▏    | 83/209 [1:38:16<2:00:46, 57.51s/it, training_loss=0.090]\u001b[A\n",
      "Epoch 3:  40%|███▏    | 84/209 [1:38:16<1:58:52, 57.06s/it, training_loss=0.090]\u001b[A\n",
      "Epoch 3:  40%|███▏    | 84/209 [1:39:08<1:58:52, 57.06s/it, training_loss=0.063]\u001b[A\n",
      "Epoch 3:  41%|███▎    | 85/209 [1:39:08<1:54:45, 55.53s/it, training_loss=0.063]\u001b[A\n",
      "Epoch 3:  41%|███▎    | 85/209 [1:40:03<1:54:45, 55.53s/it, training_loss=0.110]\u001b[A\n",
      "Epoch 3:  41%|███▎    | 86/209 [1:40:03<1:52:59, 55.12s/it, training_loss=0.110]\u001b[A\n",
      "Epoch 3:  41%|███▎    | 86/209 [1:40:54<1:52:59, 55.12s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 3:  42%|███▎    | 87/209 [1:40:54<1:49:38, 53.92s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 3:  42%|███▎    | 87/209 [1:41:44<1:49:38, 53.92s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 3:  42%|███▎    | 88/209 [1:41:44<1:46:35, 52.86s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 3:  42%|███▎    | 88/209 [1:42:35<1:46:35, 52.86s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 3:  43%|███▍    | 89/209 [1:42:35<1:44:29, 52.24s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 3:  43%|███▍    | 89/209 [1:43:25<1:44:29, 52.24s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  43%|███▍    | 90/209 [1:43:25<1:42:34, 51.72s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  43%|███▍    | 90/209 [1:44:16<1:42:34, 51.72s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 3:  44%|███▍    | 91/209 [1:44:16<1:40:53, 51.30s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 3:  44%|███▍    | 91/209 [1:45:12<1:40:53, 51.30s/it, training_loss=0.063]\u001b[A\n",
      "Epoch 3:  44%|███▌    | 92/209 [1:45:12<1:42:56, 52.79s/it, training_loss=0.063]\u001b[A\n",
      "Epoch 3:  44%|███▌    | 92/209 [1:46:07<1:42:56, 52.79s/it, training_loss=0.056]\u001b[A\n",
      "Epoch 3:  44%|███▌    | 93/209 [1:46:07<1:43:34, 53.57s/it, training_loss=0.056]\u001b[A\n",
      "Epoch 3:  44%|███▌    | 93/209 [1:47:02<1:43:34, 53.57s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 3:  45%|███▌    | 94/209 [1:47:02<1:43:00, 53.74s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 3:  45%|███▌    | 94/209 [1:47:59<1:43:00, 53.74s/it, training_loss=0.022]\u001b[A\n",
      "Epoch 3:  45%|███▋    | 95/209 [1:47:59<1:44:29, 54.99s/it, training_loss=0.022]\u001b[A\n",
      "Epoch 3:  45%|███▋    | 95/209 [1:48:58<1:44:29, 54.99s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 3:  46%|███▋    | 96/209 [1:48:58<1:45:43, 56.14s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 3:  46%|███▋    | 96/209 [1:49:49<1:45:43, 56.14s/it, training_loss=0.044]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  46%|███▋    | 97/209 [1:49:49<1:41:44, 54.50s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 3:  46%|███▋    | 97/209 [1:50:38<1:41:44, 54.50s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 3:  47%|███▊    | 98/209 [1:50:38<1:38:05, 53.02s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 3:  47%|███▊    | 98/209 [1:51:29<1:38:05, 53.02s/it, training_loss=0.073]\u001b[A\n",
      "Epoch 3:  47%|███▊    | 99/209 [1:51:29<1:35:32, 52.12s/it, training_loss=0.073]\u001b[A\n",
      "Epoch 3:  47%|███▊    | 99/209 [1:52:18<1:35:32, 52.12s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 3:  48%|███▎   | 100/209 [1:52:18<1:33:18, 51.36s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 3:  48%|███▎   | 100/209 [1:53:08<1:33:18, 51.36s/it, training_loss=0.094]\u001b[A\n",
      "Epoch 3:  48%|███▍   | 101/209 [1:53:08<1:31:43, 50.96s/it, training_loss=0.094]\u001b[A\n",
      "Epoch 3:  48%|███▍   | 101/209 [1:53:58<1:31:43, 50.96s/it, training_loss=0.106]\u001b[A\n",
      "Epoch 3:  49%|███▍   | 102/209 [1:53:58<1:30:21, 50.66s/it, training_loss=0.106]\u001b[A\n",
      "Epoch 3:  49%|███▍   | 102/209 [1:55:16<1:30:21, 50.66s/it, training_loss=0.119]\u001b[A\n",
      "Epoch 3:  49%|███▍   | 103/209 [1:55:16<1:43:52, 58.79s/it, training_loss=0.119]\u001b[A\n",
      "Epoch 3:  49%|███▍   | 103/209 [1:56:10<1:43:52, 58.79s/it, training_loss=0.124]\u001b[A\n",
      "Epoch 3:  50%|███▍   | 104/209 [1:56:10<1:40:22, 57.36s/it, training_loss=0.124]\u001b[A\n",
      "Epoch 3:  50%|███▍   | 104/209 [1:57:04<1:40:22, 57.36s/it, training_loss=0.029]\u001b[A\n",
      "Epoch 3:  50%|███▌   | 105/209 [1:57:04<1:37:45, 56.40s/it, training_loss=0.029]\u001b[A\n",
      "Epoch 3:  50%|███▌   | 105/209 [1:57:59<1:37:45, 56.40s/it, training_loss=0.032]\u001b[A\n",
      "Epoch 3:  51%|███▌   | 106/209 [1:57:59<1:35:55, 55.87s/it, training_loss=0.032]\u001b[A\n",
      "Epoch 3:  51%|███▌   | 106/209 [1:58:52<1:35:55, 55.87s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  51%|███▌   | 107/209 [1:58:52<1:33:51, 55.21s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  51%|███▌   | 107/209 [1:59:43<1:33:51, 55.21s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 3:  52%|███▌   | 108/209 [1:59:43<1:30:51, 53.98s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 3:  52%|███▌   | 108/209 [2:00:33<1:30:51, 53.98s/it, training_loss=0.135]\u001b[A\n",
      "Epoch 3:  52%|███▋   | 109/209 [2:00:33<1:27:45, 52.65s/it, training_loss=0.135]\u001b[A\n",
      "Epoch 3:  52%|███▋   | 109/209 [2:01:24<1:27:45, 52.65s/it, training_loss=0.058]\u001b[A\n",
      "Epoch 3:  53%|███▋   | 110/209 [2:01:24<1:25:50, 52.02s/it, training_loss=0.058]\u001b[A\n",
      "Epoch 3:  53%|███▋   | 110/209 [2:02:14<1:25:50, 52.02s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 3:  53%|███▋   | 111/209 [2:02:14<1:24:12, 51.55s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 3:  53%|███▋   | 111/209 [2:03:04<1:24:12, 51.55s/it, training_loss=0.065]\u001b[A\n",
      "Epoch 3:  54%|███▊   | 112/209 [2:03:04<1:22:29, 51.02s/it, training_loss=0.065]\u001b[A\n",
      "Epoch 3:  54%|███▊   | 112/209 [2:03:54<1:22:29, 51.02s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 3:  54%|███▊   | 113/209 [2:03:54<1:21:20, 50.84s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 3:  54%|███▊   | 113/209 [2:04:44<1:21:20, 50.84s/it, training_loss=0.029]\u001b[A\n",
      "Epoch 3:  55%|███▊   | 114/209 [2:04:44<1:20:04, 50.58s/it, training_loss=0.029]\u001b[A\n",
      "Epoch 3:  55%|███▊   | 114/209 [2:05:35<1:20:04, 50.58s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 3:  55%|███▊   | 115/209 [2:05:35<1:19:13, 50.57s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 3:  55%|███▊   | 115/209 [2:06:27<1:19:13, 50.57s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 3:  56%|███▉   | 116/209 [2:06:27<1:19:24, 51.23s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 3:  56%|███▉   | 116/209 [2:07:31<1:19:24, 51.23s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 3:  56%|███▉   | 117/209 [2:07:31<1:24:02, 54.81s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 3:  56%|███▉   | 117/209 [2:08:37<1:24:02, 54.81s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 3:  56%|███▉   | 118/209 [2:08:37<1:28:25, 58.30s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 3:  56%|███▉   | 118/209 [2:09:43<1:28:25, 58.30s/it, training_loss=0.051]\u001b[A\n",
      "Epoch 3:  57%|███▉   | 119/209 [2:09:43<1:30:54, 60.60s/it, training_loss=0.051]\u001b[A\n",
      "Epoch 3:  57%|███▉   | 119/209 [2:10:43<1:30:54, 60.60s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 3:  57%|████   | 120/209 [2:10:43<1:29:46, 60.53s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 3:  57%|████   | 120/209 [2:11:39<1:29:46, 60.53s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 3:  58%|████   | 121/209 [2:11:39<1:26:26, 58.94s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 3:  58%|████   | 121/209 [2:12:36<1:26:26, 58.94s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 3:  58%|████   | 122/209 [2:12:36<1:24:33, 58.32s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 3:  58%|████   | 122/209 [2:13:27<1:24:33, 58.32s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  59%|████   | 123/209 [2:13:27<1:20:51, 56.41s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  59%|████   | 123/209 [2:14:19<1:20:51, 56.41s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  59%|████▏  | 124/209 [2:14:19<1:17:49, 54.93s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  59%|████▏  | 124/209 [2:15:11<1:17:49, 54.93s/it, training_loss=0.055]\u001b[A\n",
      "Epoch 3:  60%|████▏  | 125/209 [2:15:11<1:15:48, 54.15s/it, training_loss=0.055]\u001b[A\n",
      "Epoch 3:  60%|████▏  | 125/209 [2:18:22<1:15:48, 54.15s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 3:  60%|████▏  | 126/209 [2:18:22<2:11:30, 95.06s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 3:  60%|████▏  | 126/209 [2:19:17<2:11:30, 95.06s/it, training_loss=0.065]\u001b[A\n",
      "Epoch 3:  61%|████▎  | 127/209 [2:19:17<1:53:35, 83.11s/it, training_loss=0.065]\u001b[A\n",
      "Epoch 3:  61%|████▎  | 127/209 [2:20:18<1:53:35, 83.11s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 3:  61%|████▎  | 128/209 [2:20:18<1:43:02, 76.32s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 3:  61%|████▎  | 128/209 [2:21:15<1:43:02, 76.32s/it, training_loss=0.055]\u001b[A\n",
      "Epoch 3:  62%|████▎  | 129/209 [2:21:15<1:34:20, 70.76s/it, training_loss=0.055]\u001b[A\n",
      "Epoch 3:  62%|████▎  | 129/209 [2:22:11<1:34:20, 70.76s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  62%|████▎  | 130/209 [2:22:11<1:27:13, 66.25s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  62%|████▎  | 130/209 [2:23:08<1:27:13, 66.25s/it, training_loss=0.095]\u001b[A\n",
      "Epoch 3:  63%|████▍  | 131/209 [2:23:08<1:22:40, 63.60s/it, training_loss=0.095]\u001b[A\n",
      "Epoch 3:  63%|████▍  | 131/209 [2:24:04<1:22:40, 63.60s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 3:  63%|████▍  | 132/209 [2:24:04<1:18:26, 61.12s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 3:  63%|████▍  | 132/209 [2:24:57<1:18:26, 61.12s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 3:  64%|████▍  | 133/209 [2:24:57<1:14:32, 58.84s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 3:  64%|████▍  | 133/209 [2:25:48<1:14:32, 58.84s/it, training_loss=0.087]\u001b[A\n",
      "Epoch 3:  64%|████▍  | 134/209 [2:25:48<1:10:28, 56.38s/it, training_loss=0.087]\u001b[A\n",
      "Epoch 3:  64%|████▍  | 134/209 [2:26:38<1:10:28, 56.38s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 3:  65%|████▌  | 135/209 [2:26:38<1:07:04, 54.38s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 3:  65%|████▌  | 135/209 [2:27:28<1:07:04, 54.38s/it, training_loss=0.069]\u001b[A\n",
      "Epoch 3:  65%|████▌  | 136/209 [2:27:28<1:04:39, 53.14s/it, training_loss=0.069]\u001b[A\n",
      "Epoch 3:  65%|████▌  | 136/209 [2:28:17<1:04:39, 53.14s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 3:  66%|████▌  | 137/209 [2:28:17<1:02:24, 52.01s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 3:  66%|████▌  | 137/209 [2:29:08<1:02:24, 52.01s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 3:  66%|████▌  | 138/209 [2:29:08<1:00:57, 51.51s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 3:  66%|████▌  | 138/209 [2:29:58<1:00:57, 51.51s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 3:  67%|█████▉   | 139/209 [2:29:58<59:37, 51.11s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 3:  67%|█████▉   | 139/209 [2:30:52<59:37, 51.11s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 3:  67%|██████   | 140/209 [2:30:52<59:52, 52.06s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 3:  67%|██████   | 140/209 [2:31:48<59:52, 52.06s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 3:  67%|████▋  | 141/209 [2:31:48<1:00:26, 53.33s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 3:  67%|████▋  | 141/209 [2:32:44<1:00:26, 53.33s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 3:  68%|████▊  | 142/209 [2:32:44<1:00:24, 54.10s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 3:  68%|████▊  | 142/209 [2:33:39<1:00:24, 54.10s/it, training_loss=0.062]\u001b[A\n",
      "Epoch 3:  68%|██████▏  | 143/209 [2:33:39<59:47, 54.35s/it, training_loss=0.062]\u001b[A\n",
      "Epoch 3:  68%|██████▏  | 143/209 [2:34:34<59:47, 54.35s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 3:  69%|██████▏  | 144/209 [2:34:34<58:51, 54.34s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 3:  69%|██████▏  | 144/209 [2:35:25<58:51, 54.34s/it, training_loss=0.031]\u001b[A\n",
      "Epoch 3:  69%|██████▏  | 145/209 [2:35:25<56:56, 53.39s/it, training_loss=0.031]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  69%|██████▏  | 145/209 [2:36:14<56:56, 53.39s/it, training_loss=0.107]\u001b[A\n",
      "Epoch 3:  70%|██████▎  | 146/209 [2:36:14<54:46, 52.16s/it, training_loss=0.107]\u001b[A\n",
      "Epoch 3:  70%|██████▎  | 146/209 [2:37:04<54:46, 52.16s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 3:  70%|██████▎  | 147/209 [2:37:04<53:15, 51.54s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 3:  70%|██████▎  | 147/209 [2:37:54<53:15, 51.54s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 3:  71%|██████▎  | 148/209 [2:37:54<51:53, 51.04s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 3:  71%|██████▎  | 148/209 [2:38:45<51:53, 51.04s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  71%|██████▍  | 149/209 [2:38:45<51:02, 51.04s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  71%|██████▍  | 149/209 [2:39:35<51:02, 51.04s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 3:  72%|██████▍  | 150/209 [2:39:35<49:47, 50.64s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 3:  72%|██████▍  | 150/209 [2:40:24<49:47, 50.64s/it, training_loss=0.058]\u001b[A\n",
      "Epoch 3:  72%|██████▌  | 151/209 [2:40:24<48:31, 50.21s/it, training_loss=0.058]\u001b[A\n",
      "Epoch 3:  72%|██████▌  | 151/209 [2:41:13<48:31, 50.21s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 3:  73%|██████▌  | 152/209 [2:41:13<47:19, 49.82s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 3:  73%|██████▌  | 152/209 [2:42:10<47:19, 49.82s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 3:  73%|██████▌  | 153/209 [2:42:10<48:27, 51.92s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 3:  73%|██████▌  | 153/209 [2:43:05<48:27, 51.92s/it, training_loss=0.086]\u001b[A\n",
      "Epoch 3:  74%|██████▋  | 154/209 [2:43:05<48:40, 53.10s/it, training_loss=0.086]\u001b[A\n",
      "Epoch 3:  74%|██████▋  | 154/209 [2:43:59<48:40, 53.10s/it, training_loss=0.096]\u001b[A\n",
      "Epoch 3:  74%|██████▋  | 155/209 [2:43:59<47:52, 53.19s/it, training_loss=0.096]\u001b[A\n",
      "Epoch 3:  74%|██████▋  | 155/209 [2:44:55<47:52, 53.19s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 3:  75%|██████▋  | 156/209 [2:44:55<47:39, 53.94s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 3:  75%|██████▋  | 156/209 [2:45:49<47:39, 53.94s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 3:  75%|██████▊  | 157/209 [2:45:49<46:51, 54.08s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 3:  75%|██████▊  | 157/209 [2:46:40<46:51, 54.08s/it, training_loss=0.035]\u001b[A\n",
      "Epoch 3:  76%|██████▊  | 158/209 [2:46:40<45:08, 53.12s/it, training_loss=0.035]\u001b[A\n",
      "Epoch 3:  76%|██████▊  | 158/209 [2:47:29<45:08, 53.12s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 3:  76%|██████▊  | 159/209 [2:47:29<43:20, 52.01s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 3:  76%|██████▊  | 159/209 [2:48:21<43:20, 52.01s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 3:  77%|██████▉  | 160/209 [2:48:21<42:20, 51.84s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 3:  77%|██████▉  | 160/209 [2:49:11<42:20, 51.84s/it, training_loss=0.094]\u001b[A\n",
      "Epoch 3:  77%|██████▉  | 161/209 [2:49:11<41:03, 51.32s/it, training_loss=0.094]\u001b[A\n",
      "Epoch 3:  77%|██████▉  | 161/209 [2:50:00<41:03, 51.32s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 3:  78%|██████▉  | 162/209 [2:50:00<39:41, 50.68s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 3:  78%|██████▉  | 162/209 [2:50:50<39:41, 50.68s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  78%|███████  | 163/209 [2:50:50<38:46, 50.58s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  78%|███████  | 163/209 [2:51:41<38:46, 50.58s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 3:  78%|███████  | 164/209 [2:51:41<37:52, 50.50s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 3:  78%|███████  | 164/209 [2:52:29<37:52, 50.50s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 3:  79%|███████  | 165/209 [2:52:29<36:38, 49.97s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 3:  79%|███████  | 165/209 [2:53:24<36:38, 49.97s/it, training_loss=0.075]\u001b[A\n",
      "Epoch 3:  79%|███████▏ | 166/209 [2:53:24<36:46, 51.31s/it, training_loss=0.075]\u001b[A\n",
      "Epoch 3:  79%|███████▏ | 166/209 [2:54:19<36:46, 51.31s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 3:  80%|███████▏ | 167/209 [2:54:19<36:41, 52.41s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 3:  80%|███████▏ | 167/209 [2:55:12<36:41, 52.41s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 3:  80%|███████▏ | 168/209 [2:55:12<36:04, 52.79s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 3:  80%|███████▏ | 168/209 [2:56:08<36:04, 52.79s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 3:  81%|███████▎ | 169/209 [2:56:08<35:49, 53.75s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 3:  81%|███████▎ | 169/209 [2:57:55<35:49, 53.75s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  81%|███████▎ | 170/209 [2:57:55<45:09, 69.48s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  81%|███████▎ | 170/209 [2:58:46<45:09, 69.48s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 3:  82%|███████▎ | 171/209 [2:58:46<40:30, 63.97s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 3:  82%|███████▎ | 171/209 [2:59:35<40:30, 63.97s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 3:  82%|███████▍ | 172/209 [2:59:35<36:48, 59.69s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 3:  82%|███████▍ | 172/209 [3:00:25<36:48, 59.69s/it, training_loss=0.080]\u001b[A\n",
      "Epoch 3:  83%|███████▍ | 173/209 [3:00:25<34:03, 56.77s/it, training_loss=0.080]\u001b[A\n",
      "Epoch 3:  83%|███████▍ | 173/209 [3:01:15<34:03, 56.77s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 3:  83%|███████▍ | 174/209 [3:01:15<31:55, 54.74s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 3:  83%|███████▍ | 174/209 [3:02:04<31:55, 54.74s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 3:  84%|███████▌ | 175/209 [3:02:04<30:02, 53.02s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 3:  84%|███████▌ | 175/209 [3:02:54<30:02, 53.02s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 3:  84%|███████▌ | 176/209 [3:02:54<28:40, 52.13s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 3:  84%|███████▌ | 176/209 [3:03:44<28:40, 52.13s/it, training_loss=0.086]\u001b[A\n",
      "Epoch 3:  85%|███████▌ | 177/209 [3:03:44<27:27, 51.49s/it, training_loss=0.086]\u001b[A\n",
      "Epoch 3:  85%|███████▌ | 177/209 [3:04:36<27:27, 51.49s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 3:  85%|███████▋ | 178/209 [3:04:36<26:36, 51.49s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 3:  85%|███████▋ | 178/209 [3:05:30<26:36, 51.49s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 3:  86%|███████▋ | 179/209 [3:05:30<26:07, 52.25s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 3:  86%|███████▋ | 179/209 [3:06:25<26:07, 52.25s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  86%|███████▊ | 180/209 [3:06:25<25:35, 52.96s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  86%|███████▊ | 180/209 [3:07:19<25:35, 52.96s/it, training_loss=0.036]\u001b[A\n",
      "Epoch 3:  87%|███████▊ | 181/209 [3:07:19<24:57, 53.50s/it, training_loss=0.036]\u001b[A\n",
      "Epoch 3:  87%|███████▊ | 181/209 [3:08:14<24:57, 53.50s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 3:  87%|███████▊ | 182/209 [3:08:14<24:10, 53.71s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 3:  87%|███████▊ | 182/209 [3:09:07<24:10, 53.71s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 3:  88%|███████▉ | 183/209 [3:09:07<23:15, 53.68s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 3:  88%|███████▉ | 183/209 [3:09:56<23:15, 53.68s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 3:  88%|███████▉ | 184/209 [3:09:56<21:49, 52.38s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 3:  88%|███████▉ | 184/209 [3:10:46<21:49, 52.38s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 3:  89%|███████▉ | 185/209 [3:10:46<20:34, 51.42s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 3:  89%|███████▉ | 185/209 [3:11:35<20:34, 51.42s/it, training_loss=0.103]\u001b[A\n",
      "Epoch 3:  89%|████████ | 186/209 [3:11:35<19:26, 50.70s/it, training_loss=0.103]\u001b[A\n",
      "Epoch 3:  89%|████████ | 186/209 [3:12:25<19:26, 50.70s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 3:  89%|████████ | 187/209 [3:12:25<18:31, 50.51s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 3:  89%|████████ | 187/209 [3:13:14<18:31, 50.51s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  90%|████████ | 188/209 [3:13:14<17:33, 50.18s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  90%|████████ | 188/209 [3:14:03<17:33, 50.18s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 3:  90%|████████▏| 189/209 [3:14:03<16:38, 49.91s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 3:  90%|████████▏| 189/209 [3:14:53<16:38, 49.91s/it, training_loss=0.087]\u001b[A\n",
      "Epoch 3:  91%|████████▏| 190/209 [3:14:53<15:45, 49.76s/it, training_loss=0.087]\u001b[A\n",
      "Epoch 3:  91%|████████▏| 190/209 [3:15:44<15:45, 49.76s/it, training_loss=0.056]\u001b[A\n",
      "Epoch 3:  91%|████████▏| 191/209 [3:15:44<15:05, 50.29s/it, training_loss=0.056]\u001b[A\n",
      "Epoch 3:  91%|████████▏| 191/209 [3:16:39<15:05, 50.29s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 3:  92%|████████▎| 192/209 [3:16:39<14:35, 51.48s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 3:  92%|████████▎| 192/209 [3:17:34<14:35, 51.48s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  92%|████████▎| 193/209 [3:17:34<14:04, 52.79s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  92%|████████▎| 193/209 [3:18:29<14:04, 52.79s/it, training_loss=0.045]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  93%|████████▎| 194/209 [3:18:29<13:19, 53.28s/it, training_loss=0.045]\u001b[A\n",
      "Epoch 3:  93%|████████▎| 194/209 [3:19:22<13:19, 53.28s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 3:  93%|████████▍| 195/209 [3:19:22<12:26, 53.34s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 3:  93%|████████▍| 195/209 [3:20:17<12:26, 53.34s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 3:  94%|████████▍| 196/209 [3:20:17<11:39, 53.83s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 3:  94%|████████▍| 196/209 [3:21:09<11:39, 53.83s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 3:  94%|████████▍| 197/209 [3:21:09<10:38, 53.21s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 3:  94%|████████▍| 197/209 [3:21:59<10:38, 53.21s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 3:  95%|████████▌| 198/209 [3:21:59<09:33, 52.14s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 3:  95%|████████▌| 198/209 [3:22:48<09:33, 52.14s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 3:  95%|████████▌| 199/209 [3:22:48<08:32, 51.24s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 3:  95%|████████▌| 199/209 [3:23:38<08:32, 51.24s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 3:  96%|████████▌| 200/209 [3:23:38<07:37, 50.80s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 3:  96%|████████▌| 200/209 [3:24:27<07:37, 50.80s/it, training_loss=0.071]\u001b[A\n",
      "Epoch 3:  96%|████████▋| 201/209 [3:24:27<06:43, 50.42s/it, training_loss=0.071]\u001b[A\n",
      "Epoch 3:  96%|████████▋| 201/209 [3:25:17<06:43, 50.42s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 3:  97%|████████▋| 202/209 [3:25:17<05:51, 50.17s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 3:  97%|████████▋| 202/209 [3:26:06<05:51, 50.17s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 3:  97%|████████▋| 203/209 [3:26:06<04:58, 49.82s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 3:  97%|████████▋| 203/209 [3:26:57<04:58, 49.82s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 3:  98%|████████▊| 204/209 [3:26:57<04:11, 50.26s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 3:  98%|████████▊| 204/209 [3:27:51<04:11, 50.26s/it, training_loss=0.065]\u001b[A\n",
      "Epoch 3:  98%|████████▊| 205/209 [3:27:51<03:25, 51.36s/it, training_loss=0.065]\u001b[A\n",
      "Epoch 3:  98%|████████▊| 205/209 [3:28:45<03:25, 51.36s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 3:  99%|████████▊| 206/209 [3:28:45<02:36, 52.17s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 3:  99%|████████▊| 206/209 [3:29:40<02:36, 52.17s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 3:  99%|████████▉| 207/209 [3:29:40<01:45, 52.98s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 3:  99%|████████▉| 207/209 [3:30:32<01:45, 52.98s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 3: 100%|████████▉| 208/209 [3:30:32<00:52, 52.55s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 3: 100%|████████▉| 208/209 [3:30:47<00:52, 52.55s/it, training_loss=0.156]\u001b[A\n",
      "Epoch 3: 100%|█████████| 209/209 [3:30:47<00:00, 41.31s/it, training_loss=0.156]\u001b[A\n",
      " 67%|████████████████████████▋            | 2/3 [10:50:11<3:44:11, 13451.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Training loss: 0.16193805759745922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▊                                           | 1/53 [00:07<06:29,  7.50s/it]\u001b[A\n",
      "  4%|█▋                                          | 2/53 [00:15<06:25,  7.55s/it]\u001b[A\n",
      "  6%|██▍                                         | 3/53 [00:22<06:23,  7.67s/it]\u001b[A\n",
      "  8%|███▎                                        | 4/53 [00:30<06:20,  7.78s/it]\u001b[A\n",
      "  9%|████▏                                       | 5/53 [00:38<06:13,  7.78s/it]\u001b[A\n",
      " 11%|████▉                                       | 6/53 [00:46<06:03,  7.73s/it]\u001b[A\n",
      " 13%|█████▊                                      | 7/53 [00:53<05:54,  7.72s/it]\u001b[A\n",
      " 15%|██████▋                                     | 8/53 [01:01<05:46,  7.70s/it]\u001b[A\n",
      " 17%|███████▍                                    | 9/53 [01:09<05:38,  7.69s/it]\u001b[A\n",
      " 19%|████████                                   | 10/53 [01:16<05:30,  7.69s/it]\u001b[A\n",
      " 21%|████████▉                                  | 11/53 [01:24<05:22,  7.68s/it]\u001b[A\n",
      " 23%|█████████▋                                 | 12/53 [01:32<05:14,  7.67s/it]\u001b[A\n",
      " 25%|██████████▌                                | 13/53 [01:39<05:06,  7.67s/it]\u001b[A\n",
      " 26%|███████████▎                               | 14/53 [01:47<04:59,  7.67s/it]\u001b[A\n",
      " 28%|████████████▏                              | 15/53 [01:55<04:52,  7.71s/it]\u001b[A\n",
      " 30%|████████████▉                              | 16/53 [02:03<04:45,  7.70s/it]\u001b[A\n",
      " 32%|█████████████▊                             | 17/53 [02:10<04:37,  7.71s/it]\u001b[A\n",
      " 34%|██████████████▌                            | 18/53 [02:18<04:30,  7.73s/it]\u001b[A\n",
      " 36%|███████████████▍                           | 19/53 [02:26<04:24,  7.77s/it]\u001b[A\n",
      " 38%|████████████████▏                          | 20/53 [02:34<04:16,  7.77s/it]\u001b[A\n",
      " 40%|█████████████████                          | 21/53 [02:42<04:08,  7.77s/it]\u001b[A\n",
      " 42%|█████████████████▊                         | 22/53 [02:49<04:00,  7.76s/it]\u001b[A\n",
      " 43%|██████████████████▋                        | 23/53 [02:57<03:52,  7.76s/it]\u001b[A\n",
      " 45%|███████████████████▍                       | 24/53 [03:05<03:44,  7.75s/it]\u001b[A\n",
      " 47%|████████████████████▎                      | 25/53 [03:13<03:37,  7.77s/it]\u001b[A\n",
      " 49%|█████████████████████                      | 26/53 [03:21<03:31,  7.83s/it]\u001b[A\n",
      " 51%|█████████████████████▉                     | 27/53 [03:28<03:24,  7.87s/it]\u001b[A\n",
      " 53%|██████████████████████▋                    | 28/53 [03:36<03:15,  7.84s/it]\u001b[A\n",
      " 55%|███████████████████████▌                   | 29/53 [03:44<03:07,  7.82s/it]\u001b[A\n",
      " 57%|████████████████████████▎                  | 30/53 [03:52<03:00,  7.84s/it]\u001b[A\n",
      " 58%|█████████████████████████▏                 | 31/53 [04:00<02:52,  7.86s/it]\u001b[A\n",
      " 60%|█████████████████████████▉                 | 32/53 [04:08<02:44,  7.84s/it]\u001b[A\n",
      " 62%|██████████████████████████▊                | 33/53 [04:15<02:36,  7.83s/it]\u001b[A\n",
      " 64%|███████████████████████████▌               | 34/53 [04:23<02:28,  7.83s/it]\u001b[A\n",
      " 66%|████████████████████████████▍              | 35/53 [04:31<02:20,  7.82s/it]\u001b[A\n",
      " 68%|█████████████████████████████▏             | 36/53 [04:39<02:13,  7.84s/it]\u001b[A\n",
      " 70%|██████████████████████████████             | 37/53 [04:47<02:05,  7.83s/it]\u001b[A\n",
      " 72%|██████████████████████████████▊            | 38/53 [04:55<01:57,  7.84s/it]\u001b[A\n",
      " 74%|███████████████████████████████▋           | 39/53 [05:02<01:49,  7.83s/it]\u001b[A\n",
      " 75%|████████████████████████████████▍          | 40/53 [05:10<01:41,  7.83s/it]\u001b[A\n",
      " 77%|█████████████████████████████████▎         | 41/53 [05:18<01:34,  7.84s/it]\u001b[A\n",
      " 79%|██████████████████████████████████         | 42/53 [05:26<01:26,  7.82s/it]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 43/53 [05:34<01:18,  7.81s/it]\u001b[A\n",
      " 83%|███████████████████████████████████▋       | 44/53 [05:41<01:10,  7.81s/it]\u001b[A\n",
      " 85%|████████████████████████████████████▌      | 45/53 [05:49<01:02,  7.80s/it]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 46/53 [05:57<00:54,  7.80s/it]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 47/53 [06:05<00:46,  7.79s/it]\u001b[A\n",
      " 91%|██████████████████████████████████████▉    | 48/53 [06:13<00:38,  7.79s/it]\u001b[A\n",
      " 92%|███████████████████████████████████████▊   | 49/53 [06:21<00:31,  7.81s/it]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 50/53 [06:28<00:23,  7.82s/it]\u001b[A\n",
      " 96%|█████████████████████████████████████████▍ | 51/53 [06:36<00:15,  7.89s/it]\u001b[A\n",
      " 98%|██████████████████████████████████████████▏| 52/53 [06:44<00:07,  7.87s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████| 53/53 [06:45<00:00,  7.65s/it]\u001b[A\n",
      "100%|███████████████████████████████████████| 3/3 [10:56:56<00:00, 13138.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.2106118011727648\n",
      "F1 Score (Weighted): 0.9226037793597665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "    model.train()          # Sending our model in Training mode\n",
    "    \n",
    "    loss_train_total = 0   # Setting the training loss to zero initially\n",
    "\n",
    "    # Setting up the Progress bar to Moniter the progress of training\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad() # As we not working with thew RNN's\n",
    "        \n",
    "        # As our dataloader has '3' iteams so batches will be the Tuple of '3'\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        # INPUTS\n",
    "        # Pulling out the inputs in the form of dictionary\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        # OUTPUTS\n",
    "        outputs = model(**inputs) # '**' Unpacking the dictionary stright into the input\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()           # backpropagation\n",
    "\n",
    "        # Gradient Clipping -- Taking the Grad. & gives it a NORM value ~ 1 \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "         \n",
    "        \n",
    "    torch.save(model.state_dict(), f'finetuned_BERT_epoch_{epoch}.model')\n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a18056d9-253c-4f40-97d0-06f0afa58588",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e2caa74-03ee-4faf-a1f7-46ca2e31f6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"finetuned_BERT_epoch_1.model\", \n",
    "        map_location 2= torch.device('cpu')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e2408a7-3a32-4e66-b954-56df199967d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 53/53 [07:02<00:00,  7.98s/it]\n"
     ]
    }
   ],
   "source": [
    "_, predictions, true_vals = evaluate(dataloader_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e6a31a-c01e-4655-9f12-af4e00740838",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "394e0f5b-ec8c-4876-acb0-9938445a7572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"finetuned_BERT_epoch_3.model\", \n",
    "        map_location = torch.device('cpu')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18ededea-ce02-444a-93c2-313d663774a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 53/53 [06:59<00:00,  7.91s/it]\n"
     ]
    }
   ],
   "source": [
    "_, predictions, true_vals = evaluate(dataloader_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "304175c7-bd91-40b7-b00d-0252d1aa3933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: not_hate\n",
      "Accuracy: 779/833\n",
      "\n",
      "Class: hate\n",
      "Accuracy: 759/834\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_per_class(predictions, true_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "50a07e7d-ff1d-4301-92da-d119ba6715a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: not_hate\n",
      "Accuracy: 779/833\n",
      "\n",
      "Class: hate\n",
      "Accuracy: 759/834\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_per_class(predictions, true_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe3f4a9-babf-4cd1-a582-e69a4dfcafef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
