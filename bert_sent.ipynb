{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "893242d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8441c87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Drasko they didn't cook half a bird you idiot ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Hopefully someone cooks Drasko in the next ep ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>of course you were born in serbia...you're as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>These girls are the equivalent of the irritati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>RT @YesYoureRacist: At least you're only a tin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  class\n",
       "0           0  Drasko they didn't cook half a bird you idiot ...      1\n",
       "1           1  Hopefully someone cooks Drasko in the next ep ...      1\n",
       "2           2  of course you were born in serbia...you're as ...      1\n",
       "3           3  These girls are the equivalent of the irritati...      1\n",
       "4           4  RT @YesYoureRacist: At least you're only a tin...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data into DataFrame \n",
    "df = pd.read_csv('balanced_data_combined.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b32b3f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "895c6d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Drasko they didn't cook half a bird you idiot ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Hopefully someone cooks Drasko in the next ep ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>of course you were born in serbia...you're as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>These girls are the equivalent of the irritati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>RT @YesYoureRacist: At least you're only a tin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              tweet  target\n",
       "0           0  Drasko they didn't cook half a bird you idiot ...       1\n",
       "1           1  Hopefully someone cooks Drasko in the next ep ...       1\n",
       "2           2  of course you were born in serbia...you're as ...       1\n",
       "3           3  These girls are the equivalent of the irritati...       1\n",
       "4           4  RT @YesYoureRacist: At least you're only a tin...       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.rename(columns={'text': 'tweet', 'class': 'target'})\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b81831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= df1.drop('Unnamed: 0', axis=1)\n",
    "df1.dropna(subset=['tweet'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f02795d",
   "metadata": {},
   "source": [
    "# Clean tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c4379da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(df, col):\n",
    "    \n",
    "    df[col] = df[col].apply(lambda x: re.sub(r'@[\\S]+', ' ', str(x)))\n",
    "    df[col] = df[col].apply(lambda x: re.sub(r'&[\\S]+?;', ' ', str(x)))\n",
    "    df[col] = df[col].apply(lambda x: re.sub(r'#', ' ', str(x)))\n",
    "    df[col] = df[col].apply(lambda x: re.sub(r'(\\bRT\\b|\\bQT\\b)', ' ', str(x)))\n",
    "    df[col] = df[col].apply(lambda x: re.sub(r'http[\\S]+', ' ', str(x)))\n",
    "    df[col] = df[col].apply(lambda x: re.sub(r'[^\\w\\s]', r'', str(x)))\n",
    "    df[col] = df[col].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "    df[col] = df[col].apply(lambda x: re.sub(r'\\w*\\d\\w*', r' ', str(x)))\n",
    "    df[col] = df[col].apply(lambda x: re.sub(r'\\s\\s+', ' ', str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d02d8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drasko they didnt cook half a bird you idiot mkr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hopefully someone cooks drasko in the next ep ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of course you were born in serbiayoure as fuck...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>these girls are the equivalent of the irritati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>at least youre only a tiny bit racist im not r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  target\n",
       "0   drasko they didnt cook half a bird you idiot mkr       1\n",
       "1  hopefully someone cooks drasko in the next ep ...       1\n",
       "2  of course you were born in serbiayoure as fuck...       1\n",
       "3  these girls are the equivalent of the irritati...       1\n",
       "4  at least youre only a tiny bit racist im not r...       1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_tweet(df1, 'tweet')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3a4432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8e75b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(df, col):\n",
    "    \"\"\"\n",
    "        Function to tokenize column of strings without punctuation\n",
    "        Input into word_tokenize() must be string with spaces only\n",
    "        Output is a list of tokenized words\n",
    "    \"\"\"\n",
    "    tokens = pd.DataFrame(df[col].apply(lambda x:nltk.word_tokenize(x)))\n",
    "    return tokens\n",
    "    \n",
    "        \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4dd9f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_stopwords(text):\n",
    "    \"\"\"This function returns the words in text if they are not a stop words \n",
    "       as per nltk.corpus.stopwords\n",
    "    \"\"\"\n",
    "    lst = [word for word in text if word not in stop_words]\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5153687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1[\"tokenized_tweet\"] = df1.tweet.apply(lambda x: tokenize(df1, 'tweet'))\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_list = [''.join(c for c in s if c not in string.punctuation) for s in stop_words]\n",
    "\n",
    "token_tweets = tokenize(df1,'tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efaecb6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(token_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49240882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[drasko, they, didnt, cook, half, a, bird, you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[hopefully, someone, cooks, drasko, in, the, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[of, course, you, were, born, in, serbiayoure,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[these, girls, are, the, equivalent, of, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[at, least, youre, only, a, tiny, bit, racist,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0  [drasko, they, didnt, cook, half, a, bird, you...\n",
       "1  [hopefully, someone, cooks, drasko, in, the, n...\n",
       "2  [of, course, you, were, born, in, serbiayoure,...\n",
       "3  [these, girls, are, the, equivalent, of, the, ...\n",
       "4  [at, least, youre, only, a, tiny, bit, racist,..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cef895f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_tweets = token_tweets.rename(columns={\"tweet\": \"tweet_tokens\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b554d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>target</th>\n",
       "      <th>tweet_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drasko they didnt cook half a bird you idiot mkr</td>\n",
       "      <td>1</td>\n",
       "      <td>[drasko, they, didnt, cook, half, a, bird, you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hopefully someone cooks drasko in the next ep ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[hopefully, someone, cooks, drasko, in, the, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of course you were born in serbiayoure as fuck...</td>\n",
       "      <td>1</td>\n",
       "      <td>[of, course, you, were, born, in, serbiayoure,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>these girls are the equivalent of the irritati...</td>\n",
       "      <td>1</td>\n",
       "      <td>[these, girls, are, the, equivalent, of, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>at least youre only a tiny bit racist im not r...</td>\n",
       "      <td>1</td>\n",
       "      <td>[at, least, youre, only, a, tiny, bit, racist,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  target  \\\n",
       "0   drasko they didnt cook half a bird you idiot mkr       1   \n",
       "1  hopefully someone cooks drasko in the next ep ...       1   \n",
       "2  of course you were born in serbiayoure as fuck...       1   \n",
       "3  these girls are the equivalent of the irritati...       1   \n",
       "4  at least youre only a tiny bit racist im not r...       1   \n",
       "\n",
       "                                        tweet_tokens  \n",
       "0  [drasko, they, didnt, cook, half, a, bird, you...  \n",
       "1  [hopefully, someone, cooks, drasko, in, the, n...  \n",
       "2  [of, course, you, were, born, in, serbiayoure,...  \n",
       "3  [these, girls, are, the, equivalent, of, the, ...  \n",
       "4  [at, least, youre, only, a, tiny, bit, racist,...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2= pd.concat([df1, token_tweets], axis=1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c324c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['tweet_tokens']=df2['tweet_tokens'].apply(lambda x: no_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d05bc2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>target</th>\n",
       "      <th>tweet_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drasko they didnt cook half a bird you idiot mkr</td>\n",
       "      <td>1</td>\n",
       "      <td>[drasko, didnt, cook, half, bird, idiot, mkr]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hopefully someone cooks drasko in the next ep ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[hopefully, someone, cooks, drasko, next, ep, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of course you were born in serbiayoure as fuck...</td>\n",
       "      <td>1</td>\n",
       "      <td>[course, born, serbiayoure, fucked, serbian, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>these girls are the equivalent of the irritati...</td>\n",
       "      <td>1</td>\n",
       "      <td>[girls, equivalent, irritating, asian, girls, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>at least youre only a tiny bit racist im not r...</td>\n",
       "      <td>1</td>\n",
       "      <td>[least, youre, tiny, bit, racist, im, racist, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  target  \\\n",
       "0   drasko they didnt cook half a bird you idiot mkr       1   \n",
       "1  hopefully someone cooks drasko in the next ep ...       1   \n",
       "2  of course you were born in serbiayoure as fuck...       1   \n",
       "3  these girls are the equivalent of the irritati...       1   \n",
       "4  at least youre only a tiny bit racist im not r...       1   \n",
       "\n",
       "                                        tweet_tokens  \n",
       "0      [drasko, didnt, cook, half, bird, idiot, mkr]  \n",
       "1  [hopefully, someone, cooks, drasko, next, ep, ...  \n",
       "2  [course, born, serbiayoure, fucked, serbian, f...  \n",
       "3  [girls, equivalent, irritating, asian, girls, ...  \n",
       "4  [least, youre, tiny, bit, racist, im, racist, ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bac02b1",
   "metadata": {},
   "source": [
    "# Bert tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b74dad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                          do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdc6f19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"sent_bert_token_length\"] = df2[\"tweet\"].apply(lambda x: len(tokenizer(x, add_special_tokens=False)[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb971c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>target</th>\n",
       "      <th>tweet_tokens</th>\n",
       "      <th>sent_bert_token_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drasko they didnt cook half a bird you idiot mkr</td>\n",
       "      <td>1</td>\n",
       "      <td>[drasko, didnt, cook, half, bird, idiot, mkr]</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hopefully someone cooks drasko in the next ep ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[hopefully, someone, cooks, drasko, next, ep, ...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of course you were born in serbiayoure as fuck...</td>\n",
       "      <td>1</td>\n",
       "      <td>[course, born, serbiayoure, fucked, serbian, f...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>these girls are the equivalent of the irritati...</td>\n",
       "      <td>1</td>\n",
       "      <td>[girls, equivalent, irritating, asian, girls, ...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>at least youre only a tiny bit racist im not r...</td>\n",
       "      <td>1</td>\n",
       "      <td>[least, youre, tiny, bit, racist, im, racist, ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  target  \\\n",
       "0   drasko they didnt cook half a bird you idiot mkr       1   \n",
       "1  hopefully someone cooks drasko in the next ep ...       1   \n",
       "2  of course you were born in serbiayoure as fuck...       1   \n",
       "3  these girls are the equivalent of the irritati...       1   \n",
       "4  at least youre only a tiny bit racist im not r...       1   \n",
       "\n",
       "                                        tweet_tokens  sent_bert_token_length  \n",
       "0      [drasko, didnt, cook, half, bird, idiot, mkr]                      14  \n",
       "1  [hopefully, someone, cooks, drasko, next, ep, ...                      13  \n",
       "2  [course, born, serbiayoure, fucked, serbian, f...                      17  \n",
       "3  [girls, equivalent, irritating, asian, girls, ...                      18  \n",
       "4  [least, youre, tiny, bit, racist, im, racist, ...                      16  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "932c5c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2['tweet_tokens'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25c4f70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['drasko', 'didnt', 'cook', 'half', 'bird', 'idiot', 'mkr']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['tweet_tokens'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c987b1c2",
   "metadata": {},
   "source": [
    "# Bert Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60e57b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from transformers import BertForSequenceClassification\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "115d5814",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    seed_val = 17\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    epochs = 5 \n",
    "    batch_size = 6\n",
    "    seq_length = 512\n",
    "    lr = 2e-5\n",
    "    eps = 1e-8\n",
    "    pretrained_model = 'bert-base-uncased'\n",
    "    test_size=0.15\n",
    "    random_state=42\n",
    "    add_special_tokens=True \n",
    "    return_attention_mask=True \n",
    "    pad_to_max_length=True \n",
    "    do_lower_case=False\n",
    "    return_tensors='pt'\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3130a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"seed_val\": config.seed_val,\n",
    "    \"device\":str(config.device),\n",
    "    \"epochs\":config.epochs, \n",
    "    \"batch_size\":config.batch_size,\n",
    "    \"seq_length\":config.seq_length,\n",
    "    \"lr\":config.lr,\n",
    "    \"eps\":config.eps,\n",
    "    \"pretrained_model\": config.pretrained_model,\n",
    "    \"test_size\":config.test_size,\n",
    "    \"random_state\":config.random_state,\n",
    "    \"add_special_tokens\":config.add_special_tokens,\n",
    "    \"return_attention_mask\":config.return_attention_mask,\n",
    "    \"pad_to_max_length\":config.pad_to_max_length,\n",
    "    \"do_lower_case\":config.do_lower_case,\n",
    "    \"return_tensors\":config.return_tensors,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "063070c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "device = config.device\n",
    "\n",
    "random.seed(config.seed_val)\n",
    "np.random.seed(config.seed_val)\n",
    "torch.manual_seed(config.seed_val)\n",
    "torch.cuda.manual_seed_all(config.seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04687767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df_, val_df = train_test_split(df2, \n",
    "                                    test_size=0.10, \n",
    "                                    random_state=config.random_state, stratify=df2['target'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b461629e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>target</th>\n",
       "      <th>tweet_tokens</th>\n",
       "      <th>sent_bert_token_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>call me sexist but i dont think i wanna see a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[call, sexist, dont, think, wan, na, see, wome...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5286</th>\n",
       "      <td>i cant watch charlie st cloud because i cry li...</td>\n",
       "      <td>0</td>\n",
       "      <td>[cant, watch, charlie, st, cloud, cry, like, l...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>feminism</td>\n",
       "      <td>1</td>\n",
       "      <td>[feminism]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8046</th>\n",
       "      <td>you a hoe if you crying because yo ass pregnan...</td>\n",
       "      <td>1</td>\n",
       "      <td>[hoe, crying, yo, ass, pregnant, smiles, ridin...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7217</th>\n",
       "      <td>if jeremy lin dunked on lebron in a yankees ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>[jeremy, lin, dunked, lebron, yankees, cap, ce...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  target  \\\n",
       "1655  call me sexist but i dont think i wanna see a ...       1   \n",
       "5286  i cant watch charlie st cloud because i cry li...       0   \n",
       "1050                                           feminism       1   \n",
       "8046  you a hoe if you crying because yo ass pregnan...       1   \n",
       "7217  if jeremy lin dunked on lebron in a yankees ca...       0   \n",
       "\n",
       "                                           tweet_tokens  \\\n",
       "1655  [call, sexist, dont, think, wan, na, see, wome...   \n",
       "5286  [cant, watch, charlie, st, cloud, cry, like, l...   \n",
       "1050                                         [feminism]   \n",
       "8046  [hoe, crying, yo, ass, pregnant, smiles, ridin...   \n",
       "7217  [jeremy, lin, dunked, lebron, yankees, cap, ce...   \n",
       "\n",
       "      sent_bert_token_length  \n",
       "1655                      21  \n",
       "5286                      17  \n",
       "1050                       1  \n",
       "8046                      22  \n",
       "7217                      29  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "193f0e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(config.pretrained_model, \n",
    "                                          do_lower_case=config.do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c00f66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/Users/manveerkaur/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    train_df_['tweet'].values, \n",
    "    add_special_tokens=config.add_special_tokens, \n",
    "    return_attention_mask=config.return_attention_mask, \n",
    "    pad_to_max_length=config.pad_to_max_length, \n",
    "    max_length=config.seq_length, \n",
    "    return_tensors=config.return_tensors\n",
    ")\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    val_df['tweet'].values, \n",
    "    add_special_tokens=config.add_special_tokens, \n",
    "    return_attention_mask=config.return_attention_mask, \n",
    "    pad_to_max_length=config.pad_to_max_length,\n",
    "    max_length=config.seq_length, \n",
    "    return_tensors=config.return_tensors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf3acd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(train_df_['target'].values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(val_df['target'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02c6914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6349408f-e4c8-442a-a031-72ddf31bc1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7501"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de04b2fd-296b-4f18-815f-8037c1ce37f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "834"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1047d542-ff90-4bd7-946b-09ded909306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict ={'hate': 1, 'not_hate':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e32b1d4-e2fa-4034-bec7-4a09ecf09710",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels = len(label_dict),\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e68110b4-6dca-412f-ae90-a70a79a25422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8cc3e44a-b583-446e-8b84-6aa3726fa5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# We Need two different dataloder\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train),\n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                              sampler=RandomSampler(dataset_val),\n",
    "                              batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6444629-2347-4cb8-a8a4-fbbc34ada4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cf4f8209-88ad-4ecb-96f0-12e95a73373e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manveerkaur/miniconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr = 1e-5, \n",
    "    eps = 1e-8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "abcf3980-0f56-4518-a4d6-516d2f66170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps = 0,\n",
    "    num_training_steps = len(dataloader_train)*epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc169d48-41a0-405a-ad78-1ebdc69a9d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "32834544-0183-4f7f-8e93-02767d3dcdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis = 1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fdc4d668-2961-4159-969d-4617e86b7675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis = 1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat == label]\n",
    "        y_true = labels_flat[labels_flat == label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds == label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "78c1c560-1b36-4672-a1af-666aeae43bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b5af513e-dcc5-4df5-82e8-da2d15da96c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in tqdm(dataloader_val):\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9bbfa0c9-0dae-4a34-8e12-1dd9863df6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15cbf61ea534fc0a9aef0cc2294e364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/235 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 0.40034622274180676\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb320154e1a4386b0e7839d3af8f50a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.25415504861761024\n",
      "F1 Score (Weighted): 0.9002833530446407\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/235 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Training loss: 0.19893070310354233\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82d725ffdce4f74949906a6f98b981f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.20397831527171312\n",
      "F1 Score (Weighted): 0.9316380662853923\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/235 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Training loss: 0.14719439873352963\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0acb62c1ebc4517a4bbe1c00100985c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.20411062406169045\n",
      "F1 Score (Weighted): 0.9316262673188861\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "    model.train()          # Sending our model in Training mode\n",
    "    \n",
    "    loss_train_total = 0   # Setting the training loss to zero initially\n",
    "\n",
    "    # Setting up the Progress bar to Moniter the progress of training\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad() # As we not working with thew RNN's\n",
    "        \n",
    "        # As our dataloader has '3' iteams so batches will be the Tuple of '3'\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        # INPUTS\n",
    "        # Pulling out the inputs in the form of dictionary\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        # OUTPUTS\n",
    "        outputs = model(**inputs) # '**' Unpacking the dictionary stright into the input\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()           # backpropagation\n",
    "\n",
    "        # Gradient Clipping -- Taking the Grad. & gives it a NORM value ~ 1 \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "         \n",
    "        \n",
    "    torch.save(model.state_dict(), f'finetuned_BERT_epoch_{epoch}.model')\n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a18056d9-253c-4f40-97d0-06f0afa58588",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4e2caa74-03ee-4faf-a1f7-46ca2e31f6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"finetuned_BERT_epoch_1.model\", \n",
    "        map_location = torch.device('cpu')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6e2408a7-3a32-4e66-b954-56df199967d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6971298475944f3e8c50949dbf9b0db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, predictions, true_vals = evaluate(dataloader_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75e6a31a-c01e-4655-9f12-af4e00740838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: not_hate\n",
      "Accuracy: 394/417\n",
      "\n",
      "Class: hate\n",
      "Accuracy: 357/417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "394e0f5b-ec8c-4876-acb0-9938445a7572",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mload_state_dict(\n\u001b[1;32m      2\u001b[0m     torch\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinetuned_BERT_epoch_3.model\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      4\u001b[0m         map_location \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m     )\n\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"finetuned_BERT_epoch_3.model\", \n",
    "        map_location = torch.device('cpu')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "18ededea-ce02-444a-93c2-313d663774a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a19eece6964456e8c4a7b994f7d57f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, predictions, true_vals = evaluate(dataloader_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "304175c7-bd91-40b7-b00d-0252d1aa3933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: not_hate\n",
      "Accuracy: 397/417\n",
      "\n",
      "Class: hate\n",
      "Accuracy: 380/417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_per_class(predictions, true_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a07e7d-ff1d-4301-92da-d119ba6715a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_per_class(predictions, true_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe3f4a9-babf-4cd1-a582-e69a4dfcafef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
